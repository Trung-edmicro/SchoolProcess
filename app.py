"""
School Process Application - Enhanced Version
·ª®ng d·ª•ng ch√≠nh v·ªõi c·∫•u tr√∫c modular v√† c·∫•u h√¨nh t·ª´ .env
Author: Assistant
Date: 2025-07-26
"""

import sys
import traceback
import json
import glob
import os
import re
import io
import unicodedata
from datetime import datetime
from pathlib import Path

# Third-party imports
import pandas as pd
from googleapiclient.http import MediaIoBaseDownload

# Th√™m project root v√†o Python path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from config.config_manager import get_config
from utils.menu_utils import *
from utils.file_utils import ensure_directories
from converters import JSONToExcelTemplateConverter
from processors.local_processor import LocalDataProcessor
from config.onluyen_api import OnLuyenAPIClient
from extractors import GoogleSheetsExtractor
from config.google_oauth_drive import GoogleOAuthDriveClient


class SchoolProcessApp:
    """·ª®ng d·ª•ng ch√≠nh School Process"""
    
    def __init__(self):
        """Kh·ªüi t·∫°o ·ª©ng d·ª•ng"""
        self.config = get_config()
        self.setup_directories()
        
    def setup_directories(self):
        """Thi·∫øt l·∫≠p c√°c th∆∞ m·ª•c c·∫ßn thi·∫øt"""
        paths = self.config.get_paths_config()
        required_dirs = [
            paths['input_dir'],
            paths['output_dir'],
            paths['config_dir'],
            'logs',
            'backups'
        ]
        
        if not ensure_directories(required_dirs):
            print("‚ö†Ô∏è  M·ªôt s·ªë th∆∞ m·ª•c kh√¥ng th·ªÉ t·∫°o ƒë∆∞·ª£c")
    
    def show_main_menu(self):
        """Hi·ªÉn th·ªã v√† x·ª≠ l√Ω main menu"""
        options = [
            "X·ª≠ l√Ω d·ªØ li·ªáu local (Excel files)",
            "OnLuyen API"
        ]
        
        handlers = [
            self.mode_local_processing,
            self.mode_onluyen_api
        ]
        
        run_menu_loop("SCHOOL PROCESS - MENU CH√çNH", options, handlers)
    
    def mode_local_processing(self):
        """Ch·∫ø ƒë·ªô x·ª≠ l√Ω d·ªØ li·ªáu local"""
        print_separator("X·ª¨ L√ù D·ªÆ LI·ªÜU LOCAL")
        
        try:
            
            paths = self.config.get_paths_config()
            processor = LocalDataProcessor(
                input_folder=paths['input_dir'],
                temp_folder=paths['temp_dir'],
                output_folder=paths['output_dir']
            )
            
            if not processor.validate_input_files():
                print_status("Kh√¥ng th·ªÉ ti·∫øp t·ª•c do thi·∫øu file input", "error")
                return
            
            print_status("B·∫Øt ƒë·∫ßu x·ª≠ l√Ω d·ªØ li·ªáu local...", "info")
            output_path = processor.process_local_files()
            
            if output_path:
                processor.print_summary()
                print_status(f"Ho√†n th√†nh! File output: {output_path}", "success")
            else:
                print_status("L·ªói trong qu√° tr√¨nh x·ª≠ l√Ω", "error")
                
        except ImportError:
            print_status("Local processor ch∆∞a ƒë∆∞·ª£c tri·ªÉn khai", "warning")
        except Exception as e:
            print_status(f"L·ªói x·ª≠ l√Ω local: {e}", "error")
    
    def mode_onluyen_api(self):
        """Ch·∫ø ƒë·ªô OnLuyen API Integration"""
        print_separator("ONLUYEN API INTEGRATION")
        
        # Submenu cho OnLuyen API - th√™m c√°c ch·ª©c nƒÉng l·∫•y d·ªØ li·ªáu
        options = [
            "Case 1: To√†n b·ªô d·ªØ li·ªáu",
            "Case 2: D·ªØ li·ªáu theo file import",
            "L·∫•y danh s√°ch Gi√°o vi√™n",
            "L·∫•y danh s√°ch H·ªçc sinh"
        ]
        
        handlers = [
            self._workflow_case_1_full_data,
            self._workflow_case_2_import_filtered,
            self.onluyen_get_teachers,
            self.onluyen_get_students
        ]
        
        run_menu_loop("ONLUYEN API INTEGRATION", options, handlers)
    
    def onluyen_get_teachers(self):
        """L·∫•y danh s√°ch gi√°o vi√™n v·ªõi auto-authentication"""
        print_separator("L·∫§Y DANH S√ÅCH GI√ÅO VI√äN")
        
        try:
            # H·ªèi page size v·ªõi default l·ªõn h∆°n
            page_size = get_user_input("Nh·∫≠p page size (Enter = 1000)") or "1000"
            try:
                page_size = int(page_size)
            except ValueError:
                page_size = 1000
            
            # Kh·ªüi t·∫°o client v√† auto-authenticate
            client = OnLuyenAPIClient()
            
            # Th·ª≠ load token t·ª´ file login v·ªõi auto-detect school year
            current_school_year = self._get_current_school_year_from_login_file()
            if not current_school_year:
                current_school_year = 2025  # Default
            
            print_status(f"üîç Th·ª≠ s·ª≠ d·ª•ng token cho nƒÉm h·ªçc {current_school_year}...", "info")
            
            if not client.load_token_from_login_file(school_year=current_school_year):
                print_status("‚ùå Kh√¥ng t√¨m th·∫•y token h·ª£p l·ªá. Vui l√≤ng s·ª≠ d·ª•ng workflow ho√†n ch·ªânh ƒë·ªÉ login tr∆∞·ªõc.", "error")
                print("üí° H√£y s·ª≠ d·ª•ng 'Case 1' ho·∫∑c 'Case 2' ƒë·ªÉ t·ª± ƒë·ªông login v√† l·∫•y d·ªØ li·ªáu.")
                return
            
            print_status(f"‚úÖ ƒê√£ load token cho nƒÉm {current_school_year}", "success")
            print_status(f"ƒêang l·∫•y danh s√°ch gi√°o vi√™n (page size: {page_size})...", "info")
            
            result = client.get_teachers(page_size=page_size)
            
            if result['success']:
                data = result.get('data')
                
                if data:
                    if isinstance(data, dict) and 'data' in data:
                        teachers_list = data['data']
                        teachers_count = data.get('totalCount', len(teachers_list))
                        
                        print_status(f"‚úÖ L·∫•y danh s√°ch th√†nh c√¥ng: {len(teachers_list)}/{teachers_count} gi√°o vi√™n", "success")
                        
                        if len(teachers_list) > 0:
                            print(f"\nüìã DANH S√ÅCH GI√ÅO VI√äN (hi·ªÉn th·ªã {min(len(teachers_list), 10)} ƒë·∫ßu ti√™n):")
                            for i, teacher in enumerate(teachers_list[:10], 1):
                                if isinstance(teacher, dict):
                                    name = teacher.get('name', teacher.get('fullName', 'N/A'))
                                    email = teacher.get('email', 'N/A')
                                    id_val = teacher.get('id', teacher.get('teacherId', 'N/A'))
                                    print(f"   {i:2d}. ID: {id_val} | T√™n: {name} | Email: {email}")
                            
                            if len(teachers_list) > 10:
                                print(f"   ... v√† {len(teachers_list) - 10} gi√°o vi√™n kh√°c")
                            
                            # H·ªèi c√≥ mu·ªën l∆∞u JSON kh√¥ng
                            if get_user_confirmation("L∆∞u danh s√°ch gi√°o vi√™n v√†o file JSON?"):
                                self._save_teachers_data(teachers_list, teachers_count)
                        else:
                            print_status("Kh√¥ng c√≥ gi√°o vi√™n n√†o trong danh s√°ch", "warning")
                    
                    elif isinstance(data, list):
                        print_status(f"‚úÖ L·∫•y danh s√°ch th√†nh c√¥ng! T√¨m th·∫•y {len(data)} gi√°o vi√™n", "success")
                        
                        if len(data) > 0:
                            print(f"\nüìã DANH S√ÅCH GI√ÅO VI√äN (hi·ªÉn th·ªã {min(len(data), 10)} ƒë·∫ßu ti√™n):")
                            for i, teacher in enumerate(data[:10], 1):
                                print(f"   {i:2d}. {teacher}")
                            
                            if len(data) > 10:
                                print(f"   ... v√† {len(data) - 10} gi√°o vi√™n kh√°c")
                            
                            # H·ªèi c√≥ mu·ªën l∆∞u JSON kh√¥ng
                            if get_user_confirmation("L∆∞u danh s√°ch gi√°o vi√™n v√†o file JSON?"):
                                self._save_teachers_data(data, len(data))
                        else:
                            print_status("Kh√¥ng c√≥ gi√°o vi√™n n√†o trong danh s√°ch", "warning")
                    
                    else:
                        print_status(f"‚úÖ L·∫•y d·ªØ li·ªáu th√†nh c√¥ng! Response type: {type(data)}", "success")
                        print(f"üìã DATA: {data}")
                else:
                    print_status("API tr·∫£ v·ªÅ th√†nh c√¥ng nh∆∞ng kh√¥ng c√≥ d·ªØ li·ªáu", "warning")
            else:
                print_status(f"‚ùå L·ªói l·∫•y danh s√°ch: {result.get('error', 'Unknown error')}", "error")
                if result.get('status_code'):
                    print(f"   üì° Status Code: {result.get('status_code')}")
            
        except ImportError:
            print_status("Module onluyen_api ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t", "error")
        except Exception as e:
            print_status(f"L·ªói l·∫•y danh s√°ch gi√°o vi√™n: {e}", "error")
    
    def onluyen_get_students(self):
        """L·∫•y danh s√°ch h·ªçc sinh v·ªõi auto-authentication"""
        print_separator("L·∫§Y DANH S√ÅCH H·ªåC SINH")
        
        try:
            # H·ªèi page index v√† page size v·ªõi default l·ªõn h∆°n
            page_index = get_user_input("Nh·∫≠p page index (Enter = 1)") or "1"
            page_size = get_user_input("Nh·∫≠p page size (Enter = 5000)") or "5000"
            
            try:
                page_index = int(page_index)
                page_size = int(page_size)
            except ValueError:
                page_index = 1
                page_size = 5000
            
            # Kh·ªüi t·∫°o client v√† auto-authenticate
            client = OnLuyenAPIClient()
            
            # Th·ª≠ load token t·ª´ file login v·ªõi auto-detect school year
            current_school_year = self._get_current_school_year_from_login_file()
            if not current_school_year:
                current_school_year = 2025  # Default
            
            print_status(f"üîç Th·ª≠ s·ª≠ d·ª•ng token cho nƒÉm h·ªçc {current_school_year}...", "info")
            
            if not client.load_token_from_login_file(school_year=current_school_year):
                print_status("‚ùå Kh√¥ng t√¨m th·∫•y token h·ª£p l·ªá. Vui l√≤ng s·ª≠ d·ª•ng workflow ho√†n ch·ªânh ƒë·ªÉ login tr∆∞·ªõc.", "error")
                print("üí° H√£y s·ª≠ d·ª•ng 'Case 1' ho·∫∑c 'Case 2' ƒë·ªÉ t·ª± ƒë·ªông login v√† l·∫•y d·ªØ li·ªáu.")
                return
            
            print_status(f"‚úÖ ƒê√£ load token cho nƒÉm {current_school_year}", "success")
            print_status(f"ƒêang l·∫•y danh s√°ch h·ªçc sinh (page {page_index}, size: {page_size})...", "info")
            
            result = client.get_students(page_index=page_index, page_size=page_size)
            
            if result['success']:
                data = result.get('data')
                
                if data:
                    if isinstance(data, dict) and 'data' in data:
                        students_list = data['data']
                        students_count = data.get('totalCount', len(students_list))
                        
                        print_status(f"‚úÖ L·∫•y danh s√°ch th√†nh c√¥ng: {len(students_list)}/{students_count} h·ªçc sinh", "success")
                        
                        if len(students_list) > 0:
                            print(f"\nüìã DANH S√ÅCH H·ªåC SINH (hi·ªÉn th·ªã {min(len(students_list), 10)} ƒë·∫ßu ti√™n):")
                            for i, student in enumerate(students_list[:10], 1):
                                if isinstance(student, dict):
                                    name = student.get('name', student.get('fullName', 'N/A'))
                                    email = student.get('email', 'N/A')
                                    id_val = student.get('id', student.get('studentId', 'N/A'))
                                    class_name = student.get('className', 'N/A')
                                    print(f"   {i:2d}. ID: {id_val} | T√™n: {name} | L·ªõp: {class_name}")
                                else:
                                    print(f"   {i:2d}. {student}")
                            
                            if len(students_list) > 10:
                                print(f"   ... v√† {len(students_list) - 10} h·ªçc sinh kh√°c")
                            
                            # H·ªèi c√≥ mu·ªën l∆∞u JSON kh√¥ng
                            if get_user_confirmation("L∆∞u danh s√°ch h·ªçc sinh v√†o file JSON?"):
                                self._save_students_data(students_list, students_count)
                        else:
                            print_status("Kh√¥ng c√≥ h·ªçc sinh n√†o trong danh s√°ch", "warning")
                    
                    elif isinstance(data, list):
                        print_status(f"‚úÖ L·∫•y danh s√°ch th√†nh c√¥ng! T√¨m th·∫•y {len(data)} h·ªçc sinh", "success")
                        
                        if len(data) > 0:
                            print(f"\nüìã DANH S√ÅCH H·ªåC SINH (hi·ªÉn th·ªã {min(len(data), 10)} ƒë·∫ßu ti√™n):")
                            for i, student in enumerate(data[:10], 1):
                                print(f"   {i:2d}. {student}")
                            
                            if len(data) > 10:
                                print(f"   ... v√† {len(data) - 10} h·ªçc sinh kh√°c")
                            
                            # H·ªèi c√≥ mu·ªën l∆∞u JSON kh√¥ng
                            if get_user_confirmation("L∆∞u danh s√°ch h·ªçc sinh v√†o file JSON?"):
                                self._save_students_data(data, len(data))
                        else:
                            print_status("Kh√¥ng c√≥ h·ªçc sinh n√†o trong danh s√°ch", "warning")
                    
                    else:
                        print_status(f"‚úÖ L·∫•y d·ªØ li·ªáu th√†nh c√¥ng! Response type: {type(data)}", "success")
                        print(f"üìã DATA: {data}")
                else:
                    print_status("API tr·∫£ v·ªÅ th√†nh c√¥ng nh∆∞ng kh√¥ng c√≥ d·ªØ li·ªáu", "warning")
            else:
                print_status(f"‚ùå L·ªói l·∫•y danh s√°ch: {result.get('error', 'Unknown error')}", "error")
                if result.get('status_code'):
                    print(f"   üì° Status Code: {result.get('status_code')}")
            
        except ImportError:
            print_status("Module onluyen_api ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t", "error")
        except Exception as e:
            print_status(f"L·ªói l·∫•y danh s√°ch h·ªçc sinh: {e}", "error")
    
    def _check_onluyen_auth_required(self, client) -> bool:
        """
        Ki·ªÉm tra c√≥ c·∫ßn authentication kh√¥ng
        
        Args:
            client: OnLuyenAPIClient instance
            
        Returns:
            bool: True n·∫øu c·∫ßn auth v√† ch∆∞a auth, False n·∫øu OK
        """
        if not client.auth_token:
            print_status("Ch∆∞a login. Vui l√≤ng login tr∆∞·ªõc khi s·ª≠ d·ª•ng t√≠nh nƒÉng n√†y.", "warning")
            print("üí° H√£y s·ª≠ d·ª•ng workflow ho√†n ch·ªânh ƒë·ªÉ t·ª± ƒë·ªông login.")
            return True
        return False
    
    def _log_login_response(self, response_data):
        """Log chi ti·∫øt response data"""
        if isinstance(response_data, dict):
            for key, value in response_data.items():
                # ·∫®n sensitive data nh∆∞ng v·∫´n hi·ªÉn th·ªã c·∫•u tr√∫c
                if any(sensitive in key.lower() for sensitive in ['token', 'secret', 'key', 'password']):
                    if value:
                        display_value = f"***{str(value)[-4:]}" if len(str(value)) > 4 else "***"
                    else:
                        display_value = "N/A"
                else:
                    display_value = value
                
                print(f"   {key}: {display_value}")
        else:
            print(f"   Raw Response: {response_data}")
    
    def _log_login_error(self, school_name, admin_email, result):
        """Log chi ti·∫øt l·ªói login"""
        error_info = {
            'school': school_name,
            'admin': admin_email,
            'status_code': result.get('status_code'),
            'error': result.get('error'),
            'timestamp': __import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        print(f"\nüîç CHI TI·∫æT L·ªñI:")
        for key, value in error_info.items():
            print(f"   {key}: {value}")
    
    def _save_successful_login_info(self, school_name, admin_email, result, drive_link, password=None, school_year=2025):
        """L∆∞u th√¥ng tin login th√†nh c√¥ng v·ªõi h·ªó tr·ª£ multi-year tokens"""
        try:
            # File name c·ªë ƒë·ªãnh theo admin_email
            filename = f"onluyen_login_{admin_email.replace('@', '_').replace('.', '_')}.json"
            filepath = f"data/output/{filename}"
            
            # L·∫•y data t·ª´ response
            response_data = result.get('data', {})
            
            # T·∫°o token info cho nƒÉm h·ªçc hi·ªán t·∫°i
            current_year_token = {
                'access_token': response_data.get('access_token'),
                'refresh_token': response_data.get('refresh_token'),
                'expires_in': response_data.get('expires_in'),
                'expires_at': response_data.get('expires_at'),
                'user_id': response_data.get('userId'),
                'display_name': response_data.get('display_name'),
                'account': response_data.get('account'),
                'last_updated': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
            # Load existing data n·∫øu c√≥
            existing_data = {}
            if os.path.exists(filepath):
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        existing_data = json.load(f)
                except Exception as e:
                    print_status(f"‚ö†Ô∏è Kh√¥ng th·ªÉ ƒë·ªçc file existing: {e}", "warning")
                    existing_data = {}
            
            # C·∫•u tr√∫c m·ªõi v·ªõi multi-year support
            login_info = {
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'school_name': school_name,
                'admin_email': admin_email,
                'admin_password': password,
                'drive_link': drive_link,
                'login_status': 'success',
                'current_school_year': school_year,  # NƒÉm h·ªçc hi·ªán t·∫°i
                'tokens_by_year': existing_data.get('tokens_by_year', {}),  # Gi·ªØ l·∫°i tokens c≈©
                'last_login': {
                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'school_year': school_year,
                    'status_code': result.get('status_code'),
                    'response_keys': list(response_data.keys()) if response_data else []
                }
            }
            
            # C·∫≠p nh·∫≠t token cho nƒÉm h·ªçc hi·ªán t·∫°i
            login_info['tokens_by_year'][str(school_year)] = current_year_token
            
            # Ghi file
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(login_info, f, ensure_ascii=False, indent=2)
            
            print_status(f"‚úÖ ƒê√£ l∆∞u th√¥ng tin login v√†o: {filepath}", "success")
            print_status(f"üìÖ Token cho nƒÉm h·ªçc {school_year} ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t", "info")
            
        except Exception as e:
            print_status(f"L·ªói l∆∞u th√¥ng tin login: {e}", "warning")
    
    def _workflow_case_1_full_data(self):
        self._execute_workflow_case_1()
    
    def _workflow_case_2_import_filtered(self):
        self._execute_workflow_case_2()

    def _get_authenticated_client(self, admin_email=None, password=None, school_year=None, ui_mode=False) -> tuple:
        """
        L·∫•y OnLuyenAPIClient ƒë√£ ƒë∆∞·ª£c x√°c th·ª±c v·ªõi h·ªó tr·ª£ multi-year tokens
        - ∆Øu ti√™n s·ª≠ d·ª•ng access_token t·ª´ file login theo nƒÉm h·ªçc c·ª• th·ªÉ
        - N·∫øu token kh√¥ng thu·ªôc tr∆∞·ªùng hi·ªán t·∫°i ho·∫∑c h·∫øt h·∫°n, th·ª±c hi·ªán login l·∫°i
        - T·ª± ƒë·ªông detect nƒÉm h·ªçc t·ª´ UI state ho·∫∑c file login
        
        Args:
            admin_email (str, optional): Email admin ƒë·ªÉ login n·∫øu c·∫ßn
            password (str, optional): Password ƒë·ªÉ login n·∫øu c·∫ßn
            school_year (int, optional): NƒÉm h·ªçc c·∫ßn token (2024/2025). N·∫øu None, auto-detect
            ui_mode (bool): C√≥ ph·∫£i ch·∫ø ƒë·ªô UI kh√¥ng
            
        Returns:
            tuple: (OnLuyenAPIClient, bool, dict) - (client, success, login_result)
        """
        client = OnLuyenAPIClient()
        
        # Auto-detect school year n·∫øu kh√¥ng ƒë∆∞·ª£c cung c·∫•p
        if school_year is None:
            # Th·ª≠ l·∫•y t·ª´ UI state n·∫øu c√≥ (t·ª´ main_window current_year)
            try:
                from ui import MainWindow
                if hasattr(MainWindow, '_instance') and MainWindow._instance:
                    school_year = getattr(MainWindow._instance, 'current_year', 2025)
                    print_status(f"üéØ Detected school year from UI: {school_year}", "info")
                else:
                    school_year = 2025  # Default
                    print_status(f"üéØ Using default school year: {school_year}", "info")
            except:
                # Fallback: ƒë·ªçc t·ª´ file login ho·∫∑c default
                school_year = self._get_current_school_year_from_login_file(admin_email) or 2025
                print_status(f"üéØ Auto-detected school year: {school_year}", "info")
        
        # B∆∞·ªõc 1: Th·ª≠ load token t·ª´ file login theo nƒÉm h·ªçc c·ª• th·ªÉ
        print_status(f"üîç Ki·ªÉm tra access token cho nƒÉm h·ªçc {school_year}...", "info")
        
        if client.load_token_from_login_file(admin_email, school_year):
            print_status(f"‚úÖ ƒê√£ load access token cho nƒÉm {school_year}", "success")
            
            # Ki·ªÉm tra email trong token c√≥ kh·ªõp v·ªõi tr∆∞·ªùng hi·ªán t·∫°i kh√¥ng
            if admin_email:
                token_info = client.get_current_school_year_info()
                if token_info.get('success') and token_info.get('email'):
                    token_email = token_info.get('email', '').lower()
                    current_email = admin_email.lower()
                    
                    if token_email != current_email:
                        print_status(f"‚ö†Ô∏è Token thu·ªôc v·ªÅ email kh√°c: {token_email} != {current_email}", "warning")
                        print_status("üîÑ S·∫Ω login l·∫°i v·ªõi th√¥ng tin tr∆∞·ªùng hi·ªán t·∫°i", "info")
                    else:
                        print_status(f"‚úÖ Token kh·ªõp v·ªõi email tr∆∞·ªùng hi·ªán t·∫°i: {current_email}", "success")
                        
                        # Test token b·∫±ng c√°ch g·ªçi API nh·∫π
                        print_status("üß™ Ki·ªÉm tra t√≠nh h·ª£p l·ªá c·ªßa token...", "info")
                        test_result = client.get_teachers(page_size=1)
                        
                        if test_result['success']:
                            print_status("‚úÖ Access token h·ª£p l·ªá, s·ª≠ d·ª•ng token hi·ªán c√≥", "success")
                            
                            # Hi·ªÉn th·ªã th√¥ng tin nƒÉm h·ªçc hi·ªán t·∫°i
                            client.print_current_school_year_info()
                            
                            return client, True, {"success": True, "data": {"source": "login_file", "school_year": school_year}}
                        else:
                            print_status("‚ö†Ô∏è Access token kh√¥ng h·ª£p l·ªá ho·∫∑c ƒë√£ h·∫øt h·∫°n", "warning")
                else:
                    print_status("‚ö†Ô∏è Kh√¥ng th·ªÉ l·∫•y th√¥ng tin email t·ª´ token", "warning")
            else:
                # N·∫øu kh√¥ng c√≥ admin_email ƒë·ªÉ so s√°nh, v·∫´n test token nh∆∞ c≈©
                print_status("üß™ Ki·ªÉm tra t√≠nh h·ª£p l·ªá c·ªßa token...", "info")
                test_result = client.get_teachers(page_size=1)
                
                if test_result['success']:
                    print_status("‚úÖ Access token h·ª£p l·ªá, s·ª≠ d·ª•ng token hi·ªán c√≥", "success")
                    client.print_current_school_year_info()
                    return client, True, {"success": True, "data": {"source": "login_file", "school_year": school_year}}
                else:
                    print_status("‚ö†Ô∏è Access token kh√¥ng h·ª£p l·ªá ho·∫∑c ƒë√£ h·∫øt h·∫°n", "warning")
        else:
            print_status(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y access token cho nƒÉm {school_year}", "warning")
        
        # B∆∞·ªõc 2: N·∫øu kh√¥ng c√≥ token h·ª£p l·ªá, s·ª≠ d·ª•ng ensure_valid_token
        if not admin_email or not password:
            print_status("‚ùå C·∫ßn th√¥ng tin ƒëƒÉng nh·∫≠p ƒë·ªÉ t·∫°o token m·ªõi", "error")
            return client, False, {"success": False, "error": "Thi·∫øu th√¥ng tin ƒëƒÉng nh·∫≠p"}
        
        print_status(f"üîê Th·ª±c hi·ªán ensure_valid_token cho nƒÉm {school_year}...", "info")
        
        if client.ensure_valid_token(admin_email, password, school_year):
            print_status(f"‚úÖ ƒê√£ ƒë·∫£m b·∫£o token h·ª£p l·ªá cho nƒÉm {school_year}", "success")
            
            # Hi·ªÉn th·ªã th√¥ng tin nƒÉm h·ªçc sau khi c√≥ token
            client.print_current_school_year_info()
            
            return client, True, {"success": True, "data": {"source": "ensure_valid_token", "school_year": school_year}}
        else:
            print_status(f"‚ùå Kh√¥ng th·ªÉ l·∫•y token h·ª£p l·ªá cho nƒÉm {school_year}", "error")
            return client, False, {"success": False, "error": f"Kh√¥ng th·ªÉ x√°c th·ª±c cho nƒÉm {school_year}"}

    def _get_current_school_year_from_login_file(self, admin_email=None):
        """
        L·∫•y nƒÉm h·ªçc hi·ªán t·∫°i t·ª´ file login
        
        Args:
            admin_email (str, optional): Email admin ƒë·ªÉ t√¨m file c·ª• th·ªÉ
            
        Returns:
            int: NƒÉm h·ªçc hi·ªán t·∫°i ho·∫∑c None
        """
        try:
            client = OnLuyenAPIClient()
            
            # T√¨m file login
            if admin_email:
                filename = f"onluyen_login_{admin_email.replace('@', '_').replace('.', '_')}.json"
                login_file_path = f"data/output/{filename}"
                
                if not os.path.exists(login_file_path):
                    return None
            else:
                login_file_path = client._find_latest_login_file()
                if not login_file_path:
                    return None
            
            # ƒê·ªçc file login
            with open(login_file_path, 'r', encoding='utf-8') as f:
                login_data = json.load(f)
            
            return login_data.get('current_school_year', 2025)
            
        except Exception as e:
            print_status(f"‚ö†Ô∏è L·ªói ƒë·ªçc nƒÉm h·ªçc t·ª´ file login: {e}", "warning")
            return None

    def _check_existing_school_login_data(self, admin_email, school_year=2025):
        """
        Ki·ªÉm tra xem c√≥ d·ªØ li·ªáu JSON login cho tr∆∞·ªùng n√†y hay kh√¥ng
        
        Args:
            admin_email (str): Email admin c·ªßa tr∆∞·ªùng
            school_year (int): NƒÉm h·ªçc c·∫ßn ki·ªÉm tra
            
        Returns:
            tuple: (has_data, login_file_path, token_valid)
        """
        try:
            # T·∫°o t√™n file login theo admin_email
            filename = f"onluyen_login_{admin_email.replace('@', '_').replace('.', '_')}.json"
            login_file_path = f"data/output/{filename}"
            
            if not os.path.exists(login_file_path):
                return False, None, False
            
            # ƒê·ªçc file login
            with open(login_file_path, 'r', encoding='utf-8') as f:
                login_data = json.load(f)
            
            # Ki·ªÉm tra c√≥ token cho nƒÉm h·ªçc n√†y kh√¥ng
            tokens_by_year = login_data.get('tokens_by_year', {})
            year_token = tokens_by_year.get(str(school_year))
            
            if not year_token or not year_token.get('access_token'):
                return True, login_file_path, False  # C√≥ file nh∆∞ng kh√¥ng c√≥ token h·ª£p l·ªá
            
            # Ki·ªÉm tra t√≠nh h·ª£p l·ªá c·ªßa token (basic check)
            access_token = year_token.get('access_token')
            if access_token:
                # C√≥ token, coi nh∆∞ valid (s·∫Ω ƒë∆∞·ª£c validate k·ªπ h∆°n khi s·ª≠ d·ª•ng)
                return True, login_file_path, True
            
            return True, login_file_path, False
            
        except Exception as e:
            print_status(f"‚ö†Ô∏è L·ªói ki·ªÉm tra d·ªØ li·ªáu login: {e}", "warning")
            return False, None, False

    def _ensure_authenticated_client_for_year(self, admin_email, password, school_name, drive_link, current_school_year, ui_mode=False):
        """
        ƒê·∫£m b·∫£o c√≥ OnLuyenAPIClient v·ªõi token h·ª£p l·ªá cho nƒÉm h·ªçc c·ª• th·ªÉ
        
        Args:
            admin_email (str): Email admin
            password (str): Password
            school_name (str): T√™n tr∆∞·ªùng
            drive_link (str): Drive link
            current_school_year (int): NƒÉm h·ªçc c·∫ßn token
            ui_mode (bool): C√≥ ph·∫£i UI mode
            
        Returns:
            tuple: (client, success, actual_year)
        """
        # Ki·ªÉm tra xem c√≥ d·ªØ li·ªáu JSON cho tr∆∞·ªùng n√†y ch∆∞a
        has_data, login_file_path, token_valid = self._check_existing_school_login_data(admin_email, current_school_year)
        
        # Kh·ªüi t·∫°o bi·∫øn auth_success
        auth_success = False
        login_result = None
        client = None
        
        if has_data and token_valid:
            print_status(f"‚úÖ T√¨m th·∫•y d·ªØ li·ªáu JSON h·ª£p l·ªá cho tr∆∞·ªùng {school_name}", "success")
            print_status(f"üìÑ File: {login_file_path}", "info")
            
            # S·ª≠ d·ª•ng token hi·ªán c√≥
            client = OnLuyenAPIClient()
            if client.load_token_from_login_file(admin_email, current_school_year):
                print_status(f"‚úÖ ƒê√£ load token t·ª´ file cho nƒÉm {current_school_year}", "success")
                
                # Test token ƒë·ªÉ ƒë·∫£m b·∫£o v·∫´n h·ª£p l·ªá v√† ƒë√∫ng nƒÉm h·ªçc
                test_result = client.get_teachers(page_size=1)
                if test_result['success']:
                    # Ki·ªÉm tra nƒÉm h·ªçc t·ª´ token c√≥ kh·ªõp v·ªõi nƒÉm h·ªçc mong mu·ªën
                    token_info = client.get_current_school_year_info()
                    if token_info.get('success') and token_info.get('school_year'):
                        actual_year = token_info.get('school_year')
                        if actual_year == current_school_year:
                            print_status(f"‚úÖ Token h·ª£p l·ªá cho nƒÉm {actual_year}, ti·∫øp t·ª•c s·ª≠ d·ª•ng", "success")
                            return client, True, current_school_year
                        else:
                            print_status(f"‚ö†Ô∏è Token hi·ªán c√≥ cho nƒÉm {actual_year}, c·∫ßn token cho nƒÉm {current_school_year}", "warning")
                    else:
                        print_status("‚ö†Ô∏è Kh√¥ng th·ªÉ x√°c ƒë·ªãnh nƒÉm h·ªçc t·ª´ token, c·∫ßn x√°c th·ª±c l·∫°i", "warning")
                else:
                    print_status("‚ö†Ô∏è Token ƒë√£ h·∫øt h·∫°n, c·∫ßn x√°c th·ª±c l·∫°i", "warning")
            else:
                print_status("‚ö†Ô∏è Kh√¥ng th·ªÉ load token t·ª´ file, c·∫ßn x√°c th·ª±c l·∫°i", "warning")
        else:
            if has_data:
                print_status(f"‚ö†Ô∏è C√≥ d·ªØ li·ªáu JSON nh∆∞ng token kh√¥ng h·ª£p l·ªá cho tr∆∞·ªùng {school_name}", "warning")
            else:
                print_status(f"‚ÑπÔ∏è Ch∆∞a c√≥ d·ªØ li·ªáu JSON cho tr∆∞·ªùng {school_name}", "info")
        
        # C·∫ßn x√°c th·ª±c m·ªõi
        print_status(f"üîê S·ª≠ d·ª•ng ensure_valid_token cho nƒÉm {current_school_year}...", "info")
        
        client = OnLuyenAPIClient()
        
        if not client.ensure_valid_token(admin_email, password, current_school_year):
            print_status(f"‚ùå Kh√¥ng th·ªÉ ƒë·∫£m b·∫£o token h·ª£p l·ªá cho nƒÉm {current_school_year}", "error")
            return None, False, None
        
        print_status(f"‚úÖ ƒê√£ ƒë·∫£m b·∫£o token h·ª£p l·ªá cho nƒÉm {current_school_year}", "success")
        
        # Ki·ªÉm tra l·∫°i token ƒë√£ ƒë√∫ng nƒÉm ch∆∞a
        token_info = client.get_current_school_year_info()
        actual_year = current_school_year
        
        if token_info.get('success') and token_info.get('school_year'):
            actual_year = token_info.get('school_year')
            if actual_year == current_school_year:
                print_status(f"‚úÖ X√°c nh·∫≠n token ƒë√∫ng nƒÉm h·ªçc {actual_year}", "success")
            else:
                print_status(f"‚ö†Ô∏è Token hi·ªán t·∫°i cho nƒÉm {actual_year}, kh√¥ng ph·∫£i {current_school_year}", "warning")
                print_status(f"üîÑ S·∫Ω s·ª≠ d·ª•ng d·ªØ li·ªáu cho nƒÉm {actual_year}", "info")
        else:
            print_status("‚ö†Ô∏è Kh√¥ng th·ªÉ x√°c ƒë·ªãnh nƒÉm h·ªçc t·ª´ token", "warning")
        
        return client, True, actual_year

    def _execute_workflow_case_1(self, selected_school_data, ui_mode=False):
        """Execute Case 1 workflow - to√†n b·ªô d·ªØ li·ªáu"""

        workflow_results = {
            'sheets_extraction': False,
            'api_login': False, 
            'teachers_data': False,
            'students_data': False,
            'json_saved': False,
            'excel_converted': False,
            'drive_uploaded': False,
            'school_info': {},
            'data_summary': {},
            'json_file_path': None,
            'excel_file_path': None,
            'upload_results': {}
        }
        
        try:
            # L·∫•y th√¥ng tin tr∆∞·ªùng
            school_name = selected_school_data.get('T√™n tr∆∞·ªùng', 'N/A')
            admin_email = selected_school_data.get('Admin', '')
            password = selected_school_data.get('M·∫≠t kh·∫©u', '')
            drive_link = selected_school_data.get('Link driver d·ªØ li·ªáu', 'N/A')
            
            workflow_results['school_info'] = {
                'name': school_name,
                'admin': admin_email,
                'drive_link': drive_link
            }
            
            print(f"\nüìã TH√îNG TIN TR∆Ø·ªúNG ƒê√É CH·ªåN:")
            print(f"   üè´ T√™n tr∆∞·ªùng: {school_name}")
            print(f"   üë§ Admin: {admin_email}")
            print(f"   üîó Drive Link: {drive_link[:60] + '...' if len(drive_link) > 60 else drive_link}")
            
            # Validate Drive link ngay t·ª´ ƒë·∫ßu
            if drive_link and drive_link != 'N/A' and 'drive.google.com' in drive_link:
                folder_id_preview = self._extract_drive_folder_id(drive_link)
                if folder_id_preview:
                    print(f"   ‚úÖ Drive link h·ª£p l·ªá")
                else:
                    print(f"   ‚ùå Drive link kh√¥ng h·ª£p l·ªá")
            else:
                print(f"   ‚ö†Ô∏è Kh√¥ng c√≥ Drive link h·ª£p l·ªá")
            
            if not admin_email or not password:
                print_status("‚ùå Thi·∫øu th√¥ng tin Admin email ho·∫∑c M·∫≠t kh·∫©u", "error")
                return
            
            # B∆∞·ªõc 2: X√°c th·ª±c OnLuyen API (ch·ªâ login khi c·∫ßn thi·∫øt)
            print_status("B∆Ø·ªöC 2: X√°c th·ª±c OnLuyen API", "info")
            
            # M·∫∑c ƒë·ªãnh s·ª≠ d·ª•ng nƒÉm 2025 tr·ª´ khi c√≥ thay ƒë·ªïi ni√™n kh√≥a
            current_school_year = 2025
            try:
                from ui import MainWindow
                if hasattr(MainWindow, '_instance') and MainWindow._instance:
                    ui_year = getattr(MainWindow._instance, 'current_year', None)
                    print_status(f"üéØ Ki·ªÉm tra nƒÉm h·ªçc t·ª´ UI: {ui_year}", "info")
                    if ui_year:
                        current_school_year = ui_year
                        print_status(f"üéØ S·ª≠ d·ª•ng nƒÉm h·ªçc t·ª´ UI: {current_school_year}", "info")
                    else:
                        print_status(f"üéØ S·ª≠ d·ª•ng nƒÉm h·ªçc m·∫∑c ƒë·ªãnh: {current_school_year}", "info")
                else:
                    print_status(f"üéØ S·ª≠ d·ª•ng nƒÉm h·ªçc m·∫∑c ƒë·ªãnh: {current_school_year}", "info")
            except:
                print_status(f"üéØ S·ª≠ d·ª•ng nƒÉm h·ªçc m·∫∑c ƒë·ªãnh: {current_school_year}", "info")
            
            # Ki·ªÉm tra xem c√≥ d·ªØ li·ªáu JSON cho tr∆∞·ªùng n√†y ch∆∞a

            has_data, login_file_path, token_valid = self._check_existing_school_login_data(admin_email, current_school_year)
            
            # Kh·ªüi t·∫°o bi·∫øn auth_success
            auth_success = False
            login_result = None
            client = None
            
            if has_data and token_valid:
                print_status(f"‚úÖ T√¨m th·∫•y d·ªØ li·ªáu JSON h·ª£p l·ªá cho tr∆∞·ªùng {school_name}", "success")
                print_status(f"üìÑ File: {login_file_path}", "info")
                
                # S·ª≠ d·ª•ng token hi·ªán c√≥
                client = OnLuyenAPIClient()
                if client.load_token_from_login_file(admin_email, current_school_year):
                    print_status(f"‚úÖ ƒê√£ load token t·ª´ file cho nƒÉm {current_school_year}", "success")
                    
                    # Test token ƒë·ªÉ ƒë·∫£m b·∫£o v·∫´n h·ª£p l·ªá v√† ƒë√∫ng nƒÉm h·ªçc
                    test_result = client.get_teachers(page_size=1)
                    if test_result['success']:
                        # Ki·ªÉm tra nƒÉm h·ªçc t·ª´ token c√≥ kh·ªõp v·ªõi nƒÉm h·ªçc mong mu·ªën
                        token_info = client.get_current_school_year_info()
                        if token_info.get('success') and token_info.get('school_year'):
                            actual_year = token_info.get('school_year')
                            if actual_year == current_school_year:
                                auth_success = True
                                login_result = {"success": True, "data": {"source": "existing_login_file", "school_year": current_school_year}}
                                print_status(f"‚úÖ Token h·ª£p l·ªá cho nƒÉm {actual_year}, ti·∫øp t·ª•c s·ª≠ d·ª•ng", "success")
                            else:
                                print_status(f"‚ö†Ô∏è Token hi·ªán c√≥ cho nƒÉm {actual_year}, c·∫ßn token cho nƒÉm {current_school_year}", "warning")
                                has_data = False  # Force login l·∫°i ƒë·ªÉ l·∫•y token ƒë√∫ng nƒÉm
                        else:
                            print_status("‚ö†Ô∏è Kh√¥ng th·ªÉ x√°c ƒë·ªãnh nƒÉm h·ªçc t·ª´ token, c·∫ßn login l·∫°i", "warning")
                            has_data = False  # Force login l·∫°i
                    else:
                        print_status("‚ö†Ô∏è Token ƒë√£ h·∫øt h·∫°n, c·∫ßn login l·∫°i", "warning")
                        has_data = False  # Force login l·∫°i
                else:
                    print_status("‚ö†Ô∏è Kh√¥ng th·ªÉ load token t·ª´ file, c·∫ßn login l·∫°i", "warning")
                    has_data = False  # Force login l·∫°i
            
            if not has_data or not token_valid or not auth_success:
                if has_data:
                    print_status(f"‚ö†Ô∏è C√≥ d·ªØ li·ªáu JSON nh∆∞ng token kh√¥ng h·ª£p l·ªá cho tr∆∞·ªùng {school_name}", "warning")
                else:
                    print_status(f"‚ÑπÔ∏è Ch∆∞a c√≥ d·ªØ li·ªáu JSON cho tr∆∞·ªùng {school_name}", "info")
                
                print_status(f"üîê Th·ª±c hi·ªán login m·ªõi cho nƒÉm {current_school_year}...", "info")
                
                # Th·ª±c hi·ªán login m·ªõi
                client, auth_success, login_result = self._get_authenticated_client(admin_email, password, current_school_year, ui_mode)
                
                if not auth_success:
                    print_status(f"‚ùå X√°c th·ª±c th·∫•t b·∫°i: {login_result.get('error', 'Unknown error')}", "error")
                    return
                
                # L∆∞u th√¥ng tin login m·ªõi v·ªõi c·∫•u tr√∫c JSON ƒë√∫ng
                if login_result.get('data', {}).get('source') != 'login_file':
                    print_status("üíæ L∆∞u th√¥ng tin login m·ªõi...", "info")
                    self._save_successful_login_info(school_name, admin_email, login_result, drive_link, password, current_school_year)
                    print_status(f"‚úÖ ƒê√£ t·∫°o/c·∫≠p nh·∫≠t d·ªØ li·ªáu JSON cho tr∆∞·ªùng {school_name}", "success")
            
            workflow_results['api_login'] = True
            workflow_results['school_year'] = current_school_year
            print_status(f"‚úÖ OnLuyen API x√°c th·ª±c th√†nh c√¥ng cho nƒÉm {current_school_year}", "success")
            
            # B∆∞·ªõc 3: L·∫•y danh s√°ch Gi√°o vi√™n
            print_status("B∆Ø·ªöC 3: L·∫•y danh s√°ch Gi√°o vi√™n", "info")
            
            teachers_result = client.get_teachers(page_size=1000)
            
            if teachers_result['success'] and teachers_result.get('data'):
                teachers_data = teachers_result['data']
                if isinstance(teachers_data, dict) and 'data' in teachers_data:
                    teachers_list = teachers_data['data']
                    teachers_count = teachers_data.get('totalCount', len(teachers_list))
                    
                    workflow_results['teachers_data'] = True
                    workflow_results['data_summary']['teachers'] = {
                        'total': teachers_count,
                        'retrieved': len(teachers_list)
                    }
                    
                    print_status(f"‚úÖ L·∫•y danh s√°ch gi√°o vi√™n th√†nh c√¥ng: {len(teachers_list)}/{teachers_count}", "success")
                    
                    # Extract th√¥ng tin HT/HP
                    print_status("üîç Tr√≠ch xu·∫•t th√¥ng tin Hi·ªáu tr∆∞·ªùng (HT) v√† Hi·ªáu ph√≥ (HP)", "info")
                    ht_hp_info = self._extract_ht_hp_info(teachers_data)
                    workflow_results['ht_hp_info'] = ht_hp_info
                        
                else:
                    print_status("‚ö†Ô∏è ƒê·ªãnh d·∫°ng d·ªØ li·ªáu gi√°o vi√™n kh√¥ng ƒë√∫ng", "warning")
            else:
                print_status(f"‚ùå L·ªói l·∫•y danh s√°ch gi√°o vi√™n: {teachers_result.get('error')}", "error")
            
            # B∆∞·ªõc 4: L·∫•y danh s√°ch H·ªçc sinh
            print_status("B∆Ø·ªöC 4: L·∫•y danh s√°ch H·ªçc sinh", "info")
            
            # G·ªçi API l·∫ßn ƒë·∫ßu ƒë·ªÉ bi·∫øt t·ªïng s·ªë h·ªçc sinh
            students_result = client.get_students(page_index=1, page_size=1000)
            
            if students_result['success'] and students_result.get('data'):
                students_data = students_result['data']
                if isinstance(students_data, dict) and 'data' in students_data:
                    all_students_list = []
                    students_count = students_data.get('totalCount', 0)
                    
                    print_status(f"üìä T·ªïng s·ªë h·ªçc sinh c·∫ßn l·∫•y: {students_count}", "info")
                    
                    if students_count > 0:
                        # L·∫•y d·ªØ li·ªáu t·ª´ l·∫ßn g·ªçi ƒë·∫ßu ti√™n
                        first_batch = students_data['data']
                        all_students_list.extend(first_batch)
                        print_status(f"   ‚úÖ L·∫•y ƒë∆∞·ª£c batch 1: {len(first_batch)} h·ªçc sinh", "info")
                        
                        # T√≠nh s·ªë l·∫ßn g·ªçi API c·∫ßn thi·∫øt
                        page_size = 1000  # S·ª≠ d·ª•ng page size nh·ªè h∆°n ƒë·ªÉ ƒë·∫£m b·∫£o ·ªïn ƒë·ªãnh
                        total_pages = (students_count + page_size - 1) // page_size
                        
                        # G·ªçi API cho c√°c trang c√≤n l·∫°i
                        for page_index in range(2, total_pages + 1):
                            print_status(f"   üîÑ ƒêang l·∫•y batch {page_index}/{total_pages}...", "info")
                            
                            batch_result = client.get_students(page_index=page_index, page_size=page_size)
                            
                            if batch_result['success'] and batch_result.get('data'):
                                batch_data = batch_result['data']
                                if isinstance(batch_data, dict) and 'data' in batch_data:
                                    batch_students = batch_data['data']
                                    all_students_list.extend(batch_students)
                                    print_status(f"   ‚úÖ L·∫•y ƒë∆∞·ª£c batch {page_index}: {len(batch_students)} h·ªçc sinh", "info")
                                else:
                                    print_status(f"   ‚ö†Ô∏è Batch {page_index}: ƒê·ªãnh d·∫°ng d·ªØ li·ªáu kh√¥ng ƒë√∫ng", "warning")
                            else:
                                print_status(f"   ‚ùå Batch {page_index}: {batch_result.get('error', 'L·ªói kh√¥ng x√°c ƒë·ªãnh')}", "error")
                        
                        # C·∫≠p nh·∫≠t students_result v·ªõi t·∫•t c·∫£ d·ªØ li·ªáu
                        students_result['data'] = {
                            'data': all_students_list,
                            'totalCount': students_count
                        }
                        
                        workflow_results['students_data'] = True
                        workflow_results['data_summary']['students'] = {
                            'total': students_count,
                            'retrieved': len(all_students_list)
                        }
                        
                        print_status(f"‚úÖ Ho√†n th√†nh l·∫•y danh s√°ch h·ªçc sinh: {len(all_students_list)}/{students_count}", "success")
                    else:
                        workflow_results['students_data'] = False
                        workflow_results['data_summary']['students'] = {
                            'total': 0,
                            'retrieved': 0
                        }
                        print_status("‚ö†Ô∏è Kh√¥ng c√≥ h·ªçc sinh n√†o trong h·ªá th·ªëng", "warning")
                else:
                    print_status("‚ö†Ô∏è ƒê·ªãnh d·∫°ng d·ªØ li·ªáu h·ªçc sinh kh√¥ng ƒë√∫ng", "warning")
            else:
                print_status(f"‚ùå L·ªói l·∫•y danh s√°ch h·ªçc sinh: {students_result.get('error')}", "error")
            
            # B∆∞·ªõc 5: L∆∞u d·ªØ li·ªáu workflow JSON t·ªïng h·ª£p
            print_status("B∆Ø·ªöC 5: L∆∞u d·ªØ li·ªáu workflow JSON t·ªïng h·ª£p", "info")
            
            if workflow_results['teachers_data'] or workflow_results['students_data']:
                json_file_path = self._save_unified_workflow_data(
                    workflow_results=workflow_results,
                    teachers_result=teachers_result,
                    students_result=students_result,
                    admin_password=password,
                    workflow_type="case_1"
                )
                if json_file_path:
                    workflow_results['json_saved'] = True
                    workflow_results['json_file_path'] = json_file_path
                    print_status(f"‚úÖ ƒê√£ l∆∞u d·ªØ li·ªáu JSON: {json_file_path}", "success")
                else:
                    print_status("‚ùå L·ªói l∆∞u d·ªØ li·ªáu JSON", "error")
            else:
                print_status("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ l∆∞u", "warning")
            
            # B∆∞·ªõc 6: Chuy·ªÉn ƒë·ªïi JSON ‚Üí Excel
            print_status("B∆Ø·ªöC 6: Chuy·ªÉn ƒë·ªïi JSON ‚Üí Excel", "info")
            
            if workflow_results['json_saved'] and workflow_results['json_file_path']:
                excel_file_path = self._convert_json_to_excel(workflow_results['json_file_path'])
                if excel_file_path:
                    workflow_results['excel_converted'] = True
                    workflow_results['excel_file_path'] = excel_file_path
                    print_status(f"‚úÖ ƒê√£ t·∫°o file Excel: {excel_file_path}", "success")
                else:
                    print_status("‚ùå L·ªói chuy·ªÉn ƒë·ªïi sang Excel", "error")
            else:
                print_status("‚ö†Ô∏è Kh√¥ng c√≥ file JSON ƒë·ªÉ chuy·ªÉn ƒë·ªïi", "warning")
            
            # B∆∞·ªõc 7: H·ªèi c√≥ mu·ªën upload file Excel l√™n Google Drive kh√¥ng
            print_status("B∆Ø·ªöC 7: Upload file Excel l√™n Google Drive (T√πy ch·ªçn)", "info")
            
            # Ki·ªÉm tra c√≥ file Excel ƒë·ªÉ upload kh√¥ng
            excel_file_exists = workflow_results['excel_converted'] and workflow_results['excel_file_path'] and os.path.exists(workflow_results['excel_file_path'])
            
            if excel_file_exists:
                excel_file_name = os.path.basename(workflow_results['excel_file_path'])
                excel_file_size = os.path.getsize(workflow_results['excel_file_path']) / (1024 * 1024)  # MB
                
                print(f"\nüìä FILE EXCEL S·∫¥N S√ÄNG UPLOAD:")
                print(f"   üìÑ T√™n file: {excel_file_name}")
                print(f"   üìè K√≠ch th∆∞·ªõc: {excel_file_size:.1f} MB")
                
                # Trong UI mode, kh√¥ng upload t·ª± ƒë·ªông - ƒë·ªÉ user quy·∫øt ƒë·ªãnh trong dialog
                # Trong console mode, h·ªèi ng∆∞·ªùi d√πng c√≥ mu·ªën upload kh√¥ng
                should_upload = ui_mode or get_user_confirmation("\nüì§ B·∫°n c√≥ mu·ªën upload file Excel l√™n Google Drive?")
                
                if should_upload and not ui_mode:  # Ch·ªâ upload ngay khi ·ªü console mode
                    # Validate Drive link
                    is_valid_drive_link = False
                    folder_id = None
                    
                    if drive_link and drive_link != 'N/A' and 'drive.google.com' in drive_link:
                        folder_id = self._extract_drive_folder_id(drive_link)
                        if folder_id:
                            print(f"   ‚úÖ Drive link h·ª£p l·ªá")
                            is_valid_drive_link = True
                        else:
                            print(f"   ‚ùå Kh√¥ng th·ªÉ extract folder ID t·ª´ link")
                    else:
                        # X·ª≠ l√Ω c√°c tr∆∞·ªùng h·ª£p Drive link kh√¥ng h·ª£p l·ªá
                        if not drive_link or drive_link == 'N/A':
                            print(f"   ‚ö†Ô∏è Kh√¥ng c√≥ Drive link trong Google Sheets")
                        elif drive_link and 'drive.google.com' not in drive_link:
                            print(f"   ‚ö†Ô∏è Drive link kh√¥ng ƒë√∫ng format")
                            print(f"   üí° C·∫ßn format: https://drive.google.com/drive/folders/[FOLDER_ID]")
                        
                        print(f"   ‚ùå Drive link kh√¥ng h·ª£p l·ªá")
                    
                    if is_valid_drive_link:
                        print_status(f"üì§ ƒêang upload file Excel: {excel_file_name}", "info")
                        
                        # Upload ch·ªâ file Excel
                        upload_results = self._upload_files_to_drive_oauth([workflow_results['excel_file_path']], drive_link)
                        
                        workflow_results['upload_results'] = upload_results
                        
                        if upload_results.get('success', 0) > 0:
                            workflow_results['drive_uploaded'] = True
                            print_status(f"‚úÖ Upload file Excel th√†nh c√¥ng!", "success")
                            
                            # Hi·ªÉn th·ªã URL
                            if upload_results.get('urls'):
                                print(f"\nüìÇ FILE EXCEL ƒê√É UPLOAD:")
                                print(f"   üîó {upload_results['urls'][0]}")
                        else:
                            workflow_results['drive_uploaded'] = False
                            print_status("‚ùå Upload file Excel th·∫•t b·∫°i", "error")
                            
                            # Debug th√¥ng tin l·ªói
                            if upload_results.get('errors'):
                                print(f"\nüö® CHI TI·∫æT L·ªñI:")
                                for error in upload_results['errors']:
                                    print(f"   ‚ùå {error}")
                    else:
                        workflow_results['drive_uploaded'] = False
                        print_status("‚ö†Ô∏è Kh√¥ng th·ªÉ upload do Drive link kh√¥ng h·ª£p l·ªá", "warning")
                        print("üí° H∆Ø·ªöNG D·∫™N SETUP DRIVE LINK:")
                        print("   1Ô∏è‚É£  M·ªü Google Sheets")
                        print("   2Ô∏è‚É£  T√¨m c·ªôt 'Link driver d·ªØ li·ªáu'")
                        print("   3Ô∏è‚É£  Nh·∫≠p link Drive folder th·ª±c t·∫ø")
                        print("   4Ô∏è‚É£  Format: https://drive.google.com/drive/folders/[FOLDER_ID]")
                        
                        # Trong UI mode, b·ªè qua nh·∫≠p th·ªß c√¥ng - ƒë·ªÉ user quy·∫øt ƒë·ªãnh trong dialog
                        if not ui_mode and get_user_confirmation("\nB·∫°n c√≥ mu·ªën nh·∫≠p Drive link th·ªß c√¥ng ƒë·ªÉ upload?"):
                            manual_drive_link = get_user_input("Nh·∫≠p Google Drive folder link:")
                            if manual_drive_link and 'drive.google.com' in manual_drive_link:
                                folder_id_manual = self._extract_drive_folder_id(manual_drive_link)
                                if folder_id_manual:
                                    print_status(f"üì§ Uploading v·ªõi Drive link th·ªß c√¥ng...", "info")
                                    upload_results = self._upload_files_to_drive_oauth([workflow_results['excel_file_path']], manual_drive_link)
                                    
                                    workflow_results['upload_results'] = upload_results
                                    
                                    if upload_results.get('success', 0) > 0:
                                        workflow_results['drive_uploaded'] = True
                                        print_status(f"‚úÖ Upload file Excel th√†nh c√¥ng v·ªõi Drive link th·ªß c√¥ng!", "success")
                                        if upload_results.get('urls'):
                                            print(f"\nüìÇ FILE EXCEL ƒê√É UPLOAD:")
                                            print(f"   üîó {upload_results['urls'][0]}")
                                    else:
                                        workflow_results['drive_uploaded'] = False
                                        print_status("‚ùå Upload file Excel th·∫•t b·∫°i", "error")
                                else:
                                    workflow_results['drive_uploaded'] = False
                                    print_status("‚ùå Drive link th·ªß c√¥ng kh√¥ng h·ª£p l·ªá", "error")
                            else:
                                workflow_results['drive_uploaded'] = False
                                print_status("‚ùå Drive link th·ªß c√¥ng kh√¥ng ƒë√∫ng format", "error")
                else:
                    workflow_results['drive_uploaded'] = False
                    if ui_mode:
                        print_status("‚ÑπÔ∏è Upload s·∫Ω ƒë∆∞·ª£c th·ª±c hi·ªán t·ª´ dialog", "info")
                    else:
                        print_status("‚ÑπÔ∏è B·ªè qua upload file Excel", "info")
            else:
                workflow_results['drive_uploaded'] = False
                print_status("‚ö†Ô∏è Kh√¥ng c√≥ file Excel ƒë·ªÉ upload", "warning")
            
            # B∆∞·ªõc 8: T·ªïng h·ª£p v√† b√°o c√°o k·∫øt qu·∫£
            print_status("B∆Ø·ªöC 8: T·ªïng h·ª£p k·∫øt qu·∫£", "info")
            
            self._print_workflow_summary(workflow_results)
            
            # L∆∞u d·ªØ li·ªáu v√†o file n·∫øu ch∆∞a l∆∞u (fallback)
            if not workflow_results['json_saved'] and (workflow_results['teachers_data'] or workflow_results['students_data']):
                self._save_unified_workflow_data(
                    workflow_results=workflow_results,
                    teachers_result=teachers_result,
                    students_result=students_result,
                    admin_password=password,
                    workflow_type="case_1"
                )
            
            return workflow_results
            
        except ImportError as e:
            print_status(f"Module kh√¥ng t·ªìn t·∫°i: {e}", "error")
            return None
        except Exception as e:
            print_status(f"L·ªói trong quy tr√¨nh t√≠ch h·ª£p: {e}", "error")
            return None

    def _execute_workflow_case_2(self, selected_school_data, ui_mode=False):
        """Case 2: Workflow v·ªõi so s√°nh file import"""
        
        workflow_results = {
            'sheets_extraction': False,
            'api_login': False, 
            'teachers_data': False,
            'students_data': False,
            'import_file_downloaded': False,
            'data_comparison': False,
            'json_saved': False,
            'excel_converted': False,
            'drive_uploaded': False,
            'school_info': {},
            'data_summary': {},
            'import_file_info': {},
            'comparison_results': {},
            'json_file_path': None,
            'excel_file_path': None,
            'upload_results': {}
        }
        
        try:
            # L·∫•y th√¥ng tin tr∆∞·ªùng
            school_name = selected_school_data.get('T√™n tr∆∞·ªùng', 'N/A')
            admin_email = selected_school_data.get('Admin', '')
            password = selected_school_data.get('M·∫≠t kh·∫©u', '')
            drive_link = selected_school_data.get('Link driver d·ªØ li·ªáu', 'N/A')
            
            workflow_results['school_info'] = {
                'name': school_name,
                'admin': admin_email,
                'drive_link': drive_link
            }
            
            print(f"\nüìã TH√îNG TIN TR∆Ø·ªúNG ƒê√É CH·ªåN:")
            print(f"   üè´ T√™n tr∆∞·ªùng: {school_name}")
            print(f"   üë§ Admin: {admin_email}")
            print(f"   üîó Drive Link: {drive_link[:60] + '...' if len(drive_link) > 60 else drive_link}")
            
            if not admin_email or not password:
                print_status("‚ùå Thi·∫øu th√¥ng tin Admin email ho·∫∑c M·∫≠t kh·∫©u", "error")
                return
            
            # B∆∞·ªõc 1-2: X√°c th·ª±c OnLuyen API (ch·ªâ login khi c·∫ßn thi·∫øt)
            print_status("B∆Ø·ªöC 1-2: X√°c th·ª±c OnLuyen API", "info")
            
            # Case 2 lu√¥n s·ª≠ d·ª•ng nƒÉm 2025 (b·∫•t k·ªÉ UI ch·ªçn g√¨)
            current_school_year = 2025
            
            # Ki·ªÉm tra nƒÉm h·ªçc t·ª´ UI ƒë·ªÉ th√¥ng b√°o v√† d·ª´ng n·∫øu kh√¥ng ph·∫£i 2025
            ui_year = None
            try:
                from ui import MainWindow
                if hasattr(MainWindow, '_instance') and MainWindow._instance:
                    ui_year = getattr(MainWindow._instance, 'current_year', None)
                    
            except:
                pass
            
            if ui_year and ui_year != 2025:
                print_status(f"‚ùå Workflow Case 2 ch·ªâ h·ªó tr·ª£ nƒÉm h·ªçc 2025-2026", "error")
                print_status(f"   NƒÉm h·ªçc hi·ªán t·∫°i ƒë∆∞·ª£c ch·ªçn: {ui_year}", "error")
                print_status(f"   Vui l√≤ng chuy·ªÉn v·ªÅ nƒÉm h·ªçc 2025-2026 ƒë·ªÉ ti·∫øp t·ª•c", "error")
                return None
            
            print_status(f"üéØ Workflow Case 2 s·ª≠ d·ª•ng nƒÉm h·ªçc: {current_school_year}", "info")
            
            # Ki·ªÉm tra xem c√≥ d·ªØ li·ªáu JSON cho tr∆∞·ªùng n√†y ch∆∞a
            has_data, login_file_path, token_valid = self._check_existing_school_login_data(admin_email, current_school_year)
            
            # Kh·ªüi t·∫°o bi·∫øn auth_success
            auth_success = False
            login_result = None
            client = None
            
            if has_data and token_valid:
                print_status(f"‚úÖ T√¨m th·∫•y d·ªØ li·ªáu JSON h·ª£p l·ªá cho tr∆∞·ªùng {school_name}", "success")
                print_status(f"üìÑ File: {login_file_path}", "info")
                
                # S·ª≠ d·ª•ng token hi·ªán c√≥
                client = OnLuyenAPIClient()
                if client.load_token_from_login_file(admin_email, current_school_year):
                    print_status(f"‚úÖ ƒê√£ load token t·ª´ file cho nƒÉm {current_school_year}", "success")
                    
                    # Test token ƒë·ªÉ ƒë·∫£m b·∫£o v·∫´n h·ª£p l·ªá v√† ƒë√∫ng nƒÉm h·ªçc
                    test_result = client.get_teachers(page_size=1)
                    if test_result['success']:
                        # Ki·ªÉm tra nƒÉm h·ªçc t·ª´ token c√≥ kh·ªõp v·ªõi nƒÉm h·ªçc mong mu·ªën
                        token_info = client.get_current_school_year_info()
                        if token_info.get('success') and token_info.get('school_year'):
                            actual_year = token_info.get('school_year')
                            if actual_year == current_school_year:
                                auth_success = True
                                login_result = {"success": True, "data": {"source": "existing_login_file", "school_year": current_school_year}}
                                print_status(f"‚úÖ Token h·ª£p l·ªá cho nƒÉm {actual_year}, ti·∫øp t·ª•c s·ª≠ d·ª•ng", "success")
                            else:
                                print_status(f"‚ö†Ô∏è Token hi·ªán c√≥ cho nƒÉm {actual_year}, c·∫ßn token cho nƒÉm {current_school_year}", "warning")
                                has_data = False  # Force login l·∫°i ƒë·ªÉ l·∫•y token ƒë√∫ng nƒÉm
                        else:
                            print_status("‚ö†Ô∏è Kh√¥ng th·ªÉ x√°c ƒë·ªãnh nƒÉm h·ªçc t·ª´ token, c·∫ßn login l·∫°i", "warning")
                            has_data = False  # Force login l·∫°i
                    else:
                        print_status("‚ö†Ô∏è Token ƒë√£ h·∫øt h·∫°n, c·∫ßn login l·∫°i", "warning")
                        has_data = False  # Force login l·∫°i
                else:
                    print_status("‚ö†Ô∏è Kh√¥ng th·ªÉ load token t·ª´ file, c·∫ßn login l·∫°i", "warning")
                    has_data = False  # Force login l·∫°i
            
            if not has_data or not token_valid or not auth_success:
                if has_data:
                    print_status(f"‚ö†Ô∏è C√≥ d·ªØ li·ªáu JSON nh∆∞ng token kh√¥ng h·ª£p l·ªá cho tr∆∞·ªùng {school_name}", "warning")
                else:
                    print_status(f"‚ÑπÔ∏è Ch∆∞a c√≥ d·ªØ li·ªáu JSON cho tr∆∞·ªùng {school_name}", "info")
                
                print_status(f"üîê Th·ª±c hi·ªán login m·ªõi cho nƒÉm {current_school_year}...", "info")
                
                # Th·ª±c hi·ªán login m·ªõi
                client, auth_success, login_result = self._get_authenticated_client(admin_email, password, current_school_year, ui_mode)
                
                if not auth_success:
                    print_status(f"‚ùå X√°c th·ª±c th·∫•t b·∫°i: {login_result.get('error', 'Unknown error')}", "error")
                    return
                
                # L∆∞u th√¥ng tin login m·ªõi v·ªõi c·∫•u tr√∫c JSON ƒë√∫ng
                if login_result.get('data', {}).get('source') != 'login_file':
                    print_status("üíæ L∆∞u th√¥ng tin login m·ªõi...", "info")
                    self._save_successful_login_info(school_name, admin_email, login_result, drive_link, password, current_school_year)
                    print_status(f"‚úÖ ƒê√£ t·∫°o/c·∫≠p nh·∫≠t d·ªØ li·ªáu JSON cho tr∆∞·ªùng {school_name}", "success")
            
            workflow_results['api_login'] = True
            workflow_results['school_year'] = current_school_year
            print_status(f"‚úÖ OnLuyen API x√°c th·ª±c th√†nh c√¥ng cho nƒÉm {current_school_year}", "success")
            
            # B∆∞·ªõc 3: L·∫•y danh s√°ch Gi√°o vi√™n
            print_status("B∆Ø·ªöC 3: L·∫•y danh s√°ch Gi√°o vi√™n", "info")
            
            teachers_result = client.get_teachers(page_size=1000)
            
            if teachers_result['success'] and teachers_result.get('data'):
                teachers_data = teachers_result['data']
                if isinstance(teachers_data, dict) and 'data' in teachers_data:
                    teachers_list = teachers_data['data']
                    teachers_count = teachers_data.get('totalCount', len(teachers_list))
                    
                    workflow_results['teachers_data'] = True
                    workflow_results['data_summary']['teachers'] = {
                        'total': teachers_count,
                        'retrieved': len(teachers_list)
                    }
                    workflow_results['teachers_result'] = teachers_result
                    
                    print_status(f"‚úÖ L·∫•y danh s√°ch gi√°o vi√™n th√†nh c√¥ng: {len(teachers_list)}/{teachers_count}", "success")
                else:
                    print_status("‚ö†Ô∏è ƒê·ªãnh d·∫°ng d·ªØ li·ªáu gi√°o vi√™n kh√¥ng ƒë√∫ng", "warning")
            else:
                print_status(f"‚ùå L·ªói l·∫•y danh s√°ch gi√°o vi√™n: {teachers_result.get('error')}", "error")
            
            # B∆∞·ªõc 4: L·∫•y danh s√°ch H·ªçc sinh
            print_status("B∆Ø·ªöC 4: L·∫•y danh s√°ch H·ªçc sinh", "info")
            
            # G·ªçi API l·∫ßn ƒë·∫ßu ƒë·ªÉ bi·∫øt t·ªïng s·ªë h·ªçc sinh
            students_result = client.get_students(page_index=1, page_size=1000)
            
            if students_result['success'] and students_result.get('data'):
                students_data = students_result['data']
                if isinstance(students_data, dict) and 'data' in students_data:
                    all_students_list = []
                    students_count = students_data.get('totalCount', 0)
                    
                    print_status(f"üìä T·ªïng s·ªë h·ªçc sinh c·∫ßn l·∫•y: {students_count}", "info")
                    
                    if students_count > 0:
                        # L·∫•y d·ªØ li·ªáu t·ª´ l·∫ßn g·ªçi ƒë·∫ßu ti√™n
                        first_batch = students_data['data']
                        all_students_list.extend(first_batch)
                        print_status(f"   ‚úÖ L·∫•y ƒë∆∞·ª£c batch 1: {len(first_batch)} h·ªçc sinh", "info")
                        
                        # T√≠nh s·ªë l·∫ßn g·ªçi API c·∫ßn thi·∫øt
                        page_size = 1000
                        total_pages = (students_count + page_size - 1) // page_size
                        
                        # G·ªçi API cho c√°c trang c√≤n l·∫°i
                        for page_index in range(2, total_pages + 1):
                            print_status(f"   üîÑ ƒêang l·∫•y batch {page_index}/{total_pages}...", "info")
                            
                            batch_result = client.get_students(page_index=page_index, page_size=page_size)
                            
                            if batch_result['success'] and batch_result.get('data'):
                                batch_data = batch_result['data']
                                if isinstance(batch_data, dict) and 'data' in batch_data:
                                    batch_students = batch_data['data']
                                    all_students_list.extend(batch_students)
                                    print_status(f"   ‚úÖ L·∫•y ƒë∆∞·ª£c batch {page_index}: {len(batch_students)} h·ªçc sinh", "info")
                                else:
                                    print_status(f"   ‚ö†Ô∏è Batch {page_index}: ƒê·ªãnh d·∫°ng d·ªØ li·ªáu kh√¥ng ƒë√∫ng", "warning")
                            else:
                                print_status(f"   ‚ùå Batch {page_index}: {batch_result.get('error', 'L·ªói kh√¥ng x√°c ƒë·ªãnh')}", "error")
                        
                        # C·∫≠p nh·∫≠t students_result v·ªõi t·∫•t c·∫£ d·ªØ li·ªáu
                        students_result['data'] = {
                            'data': all_students_list,
                            'totalCount': students_count
                        }
                        
                        workflow_results['students_data'] = True
                        workflow_results['data_summary']['students'] = {
                            'total': students_count,
                            'retrieved': len(all_students_list)
                        }
                        workflow_results['students_result'] = students_result
                        
                        print_status(f"‚úÖ Ho√†n th√†nh l·∫•y danh s√°ch h·ªçc sinh: {len(all_students_list)}/{students_count}", "success")
                    else:
                        workflow_results['students_data'] = False
                        workflow_results['data_summary']['students'] = {
                            'total': 0,
                            'retrieved': 0
                        }
                        workflow_results['students_result'] = students_result
                        print_status("‚ö†Ô∏è Kh√¥ng c√≥ h·ªçc sinh n√†o trong h·ªá th·ªëng", "warning")
                else:
                    print_status("‚ö†Ô∏è ƒê·ªãnh d·∫°ng d·ªØ li·ªáu h·ªçc sinh kh√¥ng ƒë√∫ng", "warning")
            else:
                print_status(f"‚ùå L·ªói l·∫•y danh s√°ch h·ªçc sinh: {students_result.get('error')}", "error")

            # Ki·ªÉm tra c√≥ ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ ti·∫øp t·ª•c kh√¥ng
            if not (workflow_results['api_login'] and (workflow_results['teachers_data'] or workflow_results['students_data'])):
                print_status("‚ùå Kh√¥ng ƒë·ªß d·ªØ li·ªáu c∆° b·∫£n ƒë·ªÉ ti·∫øp t·ª•c", "error")
                return
                return

            # B∆∞·ªõc 5: T·∫£i file import t·ª´ Google Drive
            print_status("B∆Ø·ªöC 5: T·∫£i file import t·ª´ Google Drive", "info")
            
            school_name = workflow_results['school_info'].get('name', '')
            drive_link = workflow_results['school_info'].get('drive_link', '')
            
            import_file_path = self._download_import_file(school_name, drive_link, ui_mode)
            
            if import_file_path:
                workflow_results['import_file_downloaded'] = True
                workflow_results['import_file_info'] = {
                    'file_path': import_file_path,
                    'file_name': os.path.basename(import_file_path)
                }
                print_status(f"‚úÖ ƒê√£ t·∫£i file import: {os.path.basename(import_file_path)}", "success")
            else:
                print_status("‚ùå Kh√¥ng th·ªÉ t·∫£i file import", "error")
                return
            
            # B∆∞·ªõc 6: So s√°nh v√† l·ªçc d·ªØ li·ªáu
            print_status("B∆Ø·ªöC 6: So s√°nh v√† l·ªçc d·ªØ li·ªáu", "info")
            
            comparison_results = self._compare_and_filter_data(
                workflow_results.get('teachers_result'), 
                workflow_results.get('students_result'),
                import_file_path
            )
            
            if comparison_results:
                workflow_results['data_comparison'] = True
                workflow_results['comparison_results'] = comparison_results
                
                teachers_filtered = comparison_results.get('teachers_filtered', [])
                students_filtered = comparison_results.get('students_filtered', [])
                
                print_status(f"‚úÖ So s√°nh ho√†n t·∫•t", "success")
                print(f"   üë®‚Äçüè´ Gi√°o vi√™n kh·ªõp: {len(teachers_filtered)}")
                print(f"   üë®‚Äçüéì H·ªçc sinh kh·ªõp: {len(students_filtered)}")
                
                # Ki·ªÉm tra xem c√≥ h·ªçc sinh n√†o trong h·ªá th·ªëng kh√¥ng
                students_result = workflow_results.get('students_result', {})
                has_students_in_system = False
                if students_result and students_result.get('success') and students_result.get('data'):
                    students_data = students_result['data']
                    if isinstance(students_data, dict):
                        total_students = students_data.get('totalCount', 0)
                        has_students_in_system = total_students > 0
                    elif isinstance(students_data, list):
                        has_students_in_system = len(students_data) > 0
                
                if not has_students_in_system:
                    print_status("‚ö†Ô∏è H·ªá th·ªëng kh√¥ng c√≥ h·ªçc sinh n√†o - File Excel s·∫Ω ch·ªâ c√≥ sheet GIAO-VIEN", "warning")
                    workflow_results['no_students_in_system'] = True
                else:
                    workflow_results['no_students_in_system'] = False
                
                # C·∫≠p nh·∫≠t data_summary v·ªõi d·ªØ li·ªáu ƒë√£ l·ªçc
                workflow_results['data_summary']['teachers_filtered'] = len(teachers_filtered)
                workflow_results['data_summary']['students_filtered'] = len(students_filtered)
                workflow_results['data_summary']['has_students_in_system'] = has_students_in_system
            else:
                print_status("‚ùå L·ªói so s√°nh d·ªØ li·ªáu", "error")
                return
            

            # B∆∞·ªõc 7: L∆∞u d·ªØ li·ªáu ƒë√£ l·ªçc v√†o JSON t·ªïng h·ª£p
            print_status("B∆Ø·ªöC 7: L∆∞u d·ªØ li·ªáu ƒë√£ l·ªçc workflow JSON t·ªïng h·ª£p", "info")
            
            json_file_path = self._save_unified_workflow_data(
                workflow_results=workflow_results,
                teachers_result=workflow_results.get('teachers_result'),
                students_result=workflow_results.get('students_result'),
                comparison_results=comparison_results,
                admin_password=selected_school_data.get('M·∫≠t kh·∫©u'),
                workflow_type="case_2"
            )
            if json_file_path:
                workflow_results['json_saved'] = True
                workflow_results['json_file_path'] = json_file_path
                print_status(f"‚úÖ ƒê√£ l∆∞u d·ªØ li·ªáu ƒë√£ l·ªçc: {json_file_path}", "success")
            else:
                print_status("‚ùå L·ªói l∆∞u d·ªØ li·ªáu JSON", "error")
            
            # B∆∞·ªõc 8: Chuy·ªÉn ƒë·ªïi JSON ‚Üí Excel
            print_status("B∆Ø·ªöC 8: Chuy·ªÉn ƒë·ªïi JSON ‚Üí Excel", "info")
            
            if workflow_results['json_saved'] and workflow_results['json_file_path']:
                excel_file_path = self._convert_json_to_excel(workflow_results['json_file_path'])
                if excel_file_path:
                    workflow_results['excel_converted'] = True
                    workflow_results['excel_file_path'] = excel_file_path
                    print_status(f"‚úÖ ƒê√£ t·∫°o file Excel: {excel_file_path}", "success")
                else:
                    print_status("‚ùå L·ªói chuy·ªÉn ƒë·ªïi sang Excel", "error")
            else:
                print_status("‚ö†Ô∏è Kh√¥ng c√≥ file JSON ƒë·ªÉ chuy·ªÉn ƒë·ªïi", "warning")
            
            # B∆∞·ªõc 9: Upload files l√™n Google Drive  
            print_status("B∆Ø·ªöC 9: Upload file Excel l√™n Google Drive (T√πy ch·ªçn)", "info")
            
            excel_file_exists = workflow_results['excel_converted'] and workflow_results['excel_file_path'] and os.path.exists(workflow_results['excel_file_path'])
            
            if excel_file_exists:
                # Trong UI mode, kh√¥ng upload t·ª± ƒë·ªông - ƒë·ªÉ user quy·∫øt ƒë·ªãnh trong dialog
                # Trong console mode, h·ªèi ng∆∞·ªùi d√πng c√≥ mu·ªën upload kh√¥ng
                should_upload = ui_mode or get_user_confirmation("\nüì§ B·∫°n c√≥ mu·ªën upload file Excel l√™n Google Drive?")
                
                if should_upload and not ui_mode:  # Ch·ªâ upload ngay khi ·ªü console mode
                    # Upload ch·ªâ file Excel
                    upload_results = self._upload_files_to_drive_oauth([workflow_results['excel_file_path']], drive_link)
                    
                    workflow_results['upload_results'] = upload_results
                    
                    if upload_results.get('success', 0) > 0:
                        workflow_results['drive_uploaded'] = True
                        print_status(f"‚úÖ Upload file Excel th√†nh c√¥ng!", "success")
                    else:
                        workflow_results['drive_uploaded'] = False
                        print_status("‚ùå Upload file Excel th·∫•t b·∫°i", "error")
                else:
                    workflow_results['drive_uploaded'] = False
                    if ui_mode:
                        print_status("‚ÑπÔ∏è Upload s·∫Ω ƒë∆∞·ª£c th·ª±c hi·ªán t·ª´ dialog", "info")
                    else:
                        print_status("‚ÑπÔ∏è B·ªè qua upload file Excel", "info")
            else:
                workflow_results['drive_uploaded'] = False
                print_status("‚ö†Ô∏è Kh√¥ng c√≥ file Excel ƒë·ªÉ upload", "warning")
            
            # B∆∞·ªõc 10: T·ªïng h·ª£p v√† b√°o c√°o k·∫øt qu·∫£
            print_status("B∆Ø·ªöC 10: T·ªïng h·ª£p k·∫øt qu·∫£", "info")
            
            self._print_workflow_summary_case_2(workflow_results)
            
            return workflow_results
            
        except ImportError as e:
            print_status(f"Module kh√¥ng t·ªìn t·∫°i: {e}", "error")
            return None
        except Exception as e:
            print_status(f"L·ªói trong quy tr√¨nh Case 2: {e}", "error")
            return None

    def _convert_json_to_excel(self, json_file_path):
        """Chuy·ªÉn ƒë·ªïi file JSON workflow sang Excel"""
        try:
            
            print(f"   üìÑ File JSON: {Path(json_file_path).name}")
            
            # Kh·ªüi t·∫°o converter
            converter = JSONToExcelTemplateConverter(json_file_path)
            
            # Load v√† ki·ªÉm tra JSON data
            if not converter.load_json_data():
                print("   ‚ùå Kh√¥ng th·ªÉ load JSON data")
                return None
            
            # Extract data
            print("   üìä ƒêang tr√≠ch xu·∫•t d·ªØ li·ªáu...")
            teachers_extracted = converter.extract_teachers_data()
            students_extracted = converter.extract_students_data()
            
            if not teachers_extracted and not students_extracted:
                print("   ‚ùå Kh√¥ng th·ªÉ tr√≠ch xu·∫•t d·ªØ li·ªáu gi√°o vi√™n ho·∫∑c h·ªçc sinh")
                return None
            
            # Convert to Excel
            print("   üìù ƒêang t·∫°o file Excel...")
            output_path = converter.convert()
            
            if output_path:
                # Hi·ªÉn th·ªã th·ªëng k√™
                teachers_count = len(converter.teachers_df) if converter.teachers_df is not None else 0
                students_count = len(converter.students_df) if converter.students_df is not None else 0
                
                print(f"   üë®‚Äçüè´ S·ªë gi√°o vi√™n: {teachers_count}")
                print(f"   üë®‚Äçüéì S·ªë h·ªçc sinh: {students_count}")
                
                return output_path
            else:
                print("   ‚ùå L·ªói t·∫°o file Excel")
                return None
                
        except ImportError:
            print("   ‚ùå Module json_to_excel_template_converter ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t")
            return None
        except Exception as e:
            print(f"   ‚ùå L·ªói chuy·ªÉn ƒë·ªïi: {e}")
            return None

    def _get_drive_link_from_workflow_files(self):
        """T√¨m Drive link t·ª´ workflow files c√≥ s·∫µn"""
        try:
            
            # T√¨m files workflow JSON
            json_patterns = [
                "data/output/data_*.json",
                "data/output/workflow_data_*.json"
            ]
            
            json_files = []
            for pattern in json_patterns:
                json_files.extend(glob.glob(pattern))
            
            if not json_files:
                return None
            
            # L·∫•y file m·ªõi nh·∫•t
            latest_file = max(json_files, key=lambda f: os.path.getmtime(f))
            
            with open(latest_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # T√¨m drive link trong school_info
            drive_link = data.get('school_info', {}).get('drive_link')
            
            if drive_link and drive_link != 'N/A' and 'drive.google.com' in drive_link:
                return drive_link
            
            return None
            
        except Exception as e:
            return None
    
    def upload_to_drive(self, json_file_path, excel_file_path, drive_link, school_name):
        """
        Upload file Excel to Google Drive - Wrapper method cho UI
        
        Args:
            json_file_path (str): ƒê∆∞·ªùng d·∫´n file JSON (kh√¥ng s·ª≠ d·ª•ng, ch·ªâ ƒë·ªÉ compatibility)
            excel_file_path (str): ƒê∆∞·ªùng d·∫´n file Excel
            drive_link (str): Link Google Drive folder
            school_name (str): T√™n tr∆∞·ªùng
            
        Returns:
            dict: K·∫øt qu·∫£ upload {'success': bool, 'error': str}
        """
        try:
            # Ch·ªâ upload file Excel, kh√¥ng upload file JSON
            files_to_upload = []
            
            if excel_file_path and os.path.exists(excel_file_path):
                files_to_upload.append(excel_file_path)
            
            # Kh√¥ng th√™m JSON file v√†o danh s√°ch upload
            # if json_file_path and os.path.exists(json_file_path):
            #     files_to_upload.append(json_file_path)
            
            if not files_to_upload:
                return {'success': False, 'error': 'Kh√¥ng c√≥ file Excel ƒë·ªÉ upload'}
            
            # Validate Drive link
            if not drive_link or drive_link == 'N/A' or 'drive.google.com' not in drive_link:
                return {'success': False, 'error': 'Drive link kh√¥ng h·ª£p l·ªá'}
            
            folder_id = self._extract_drive_folder_id(drive_link)
            if not folder_id:
                return {'success': False, 'error': 'Kh√¥ng th·ªÉ extract folder ID t·ª´ Drive link'}
            
            print_status(f"üì§ ƒêang upload file Excel cho tr∆∞·ªùng: {school_name}", "info")
            
            # Th·ª±c hi·ªán upload
            upload_results = self._upload_files_to_drive_oauth(files_to_upload, drive_link)
            
            if upload_results.get('success', 0) > 0:
                return {
                    'success': True,
                    'uploaded_count': upload_results.get('success', 0),
                    'urls': upload_results.get('urls', [])
                }
            else:
                errors = upload_results.get('errors', ['Unknown error'])
                return {'success': False, 'error': '; '.join(errors)}
                
        except Exception as e:
            return {'success': False, 'error': str(e)}

    def _upload_files_to_drive_oauth(self, file_paths, drive_link):
        """
        Upload files l√™n Google Drive s·ª≠ d·ª•ng OAuth 2.0
        
        Args:
            file_paths: List ƒë∆∞·ªùng d·∫´n files c·∫ßn upload
            drive_link: Link Google Drive folder
            
        Returns:
            dict: K·∫øt qu·∫£ upload {'success': int, 'failed': int, 'urls': list, 'errors': list}
        """
        result = {
            'success': 0,
            'failed': 0,
            'urls': [],
            'errors': []
        }
        
        try:
            # Kh·ªüi t·∫°o OAuth client
            oauth_client = GoogleOAuthDriveClient()
            
            # Ki·ªÉm tra authentication
            if not oauth_client.is_authenticated():
                error_msg = "OAuth ch∆∞a ƒë∆∞·ª£c setup ho·∫∑c token h·∫øt h·∫°n"
                print_status(f"‚ùå {error_msg}", "error")
                result['failed'] = len(file_paths)
                result['errors'].append(error_msg)
                return result
            
            # Test connection
            if not oauth_client.test_connection():
                error_msg = "OAuth connection test th·∫•t b·∫°i"
                print_status(f"‚ùå {error_msg}", "error")
                result['failed'] = len(file_paths)
                result['errors'].append(error_msg)
                return result
            
            # Extract folder ID t·ª´ drive link
            folder_id = self._extract_drive_folder_id(drive_link)
            if not folder_id:
                error_msg = "Kh√¥ng th·ªÉ extract folder ID t·ª´ drive link"
                print_status(f"‚ùå {error_msg}", "error")
                result['failed'] = len(file_paths)
                result['errors'].append(error_msg)
                return result
            
            # Upload t·ª´ng file
            for file_path in file_paths:
                if not file_path or not os.path.exists(file_path):
                    result['failed'] += 1
                    error_msg = f"File kh√¥ng t·ªìn t·∫°i: {file_path}"
                    result['errors'].append(error_msg)
                    continue
                
                file_name = os.path.basename(file_path)
                print_status(f"üì§ ƒêang upload: {file_name}", "info")
                
                try:
                    file_url = oauth_client.upload_file_to_folder_id(
                        local_path=file_path,
                        folder_id=folder_id,
                        filename=file_name
                    )
                    
                    if file_url:
                        result['success'] += 1
                        result['urls'].append(file_url)
                        print(f"   ‚úÖ Upload th√†nh c√¥ng")
                    else:
                        result['failed'] += 1
                        error_msg = f"Upload th·∫•t b·∫°i cho {file_name}"
                        result['errors'].append(error_msg)
                        print(f"   ‚ùå Upload th·∫•t b·∫°i")
                        
                except Exception as e:
                    result['failed'] += 1
                    error_msg = f"L·ªói upload {file_name}: {str(e)}"
                    result['errors'].append(error_msg)
                    print_status(f"‚ùå L·ªói upload {file_name}: {e}", "error")
            
            return result
            
        except ImportError as e:
            error_msg = f"OAuth module ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t: {e}"
            print_status(f"‚ùå {error_msg}", "error")
            result['failed'] = len(file_paths)
            result['errors'].append(error_msg)
            return result
        except Exception as e:
            error_msg = f"L·ªói OAuth upload: {e}"
            print_status(f"‚ùå {error_msg}", "error")
            result['failed'] = len(file_paths)
            result['errors'].append(error_msg)
            return result

    def _extract_drive_folder_id(self, drive_link):
        """Extract folder ID t·ª´ Google Drive link"""
        try:
            # Patterns cho Drive folder links
            patterns = [
                r'drive\.google\.com/drive/folders/([a-zA-Z0-9-_]+)',
                r'drive\.google\.com/drive/u/\d+/folders/([a-zA-Z0-9-_]+)',
                r'drive\.google\.com/open\?id=([a-zA-Z0-9-_]+)',
                r'/folders/([a-zA-Z0-9-_]+)',
                r'id=([a-zA-Z0-9-_]+)'
            ]
            
            for pattern in patterns:
                match = re.search(pattern, drive_link)
                if match:
                    return match.group(1)
            
            print_status("‚ùå Kh√¥ng th·ªÉ extract folder ID t·ª´ link", "error")
            return None
            
        except Exception as e:
            print_status(f"‚ùå L·ªói extract folder ID: {e}", "error")
            return None

    def _print_workflow_summary(self, results):
        # T·ªïng k·∫øt
        success_count = sum([results['sheets_extraction'], results['api_login'], 
                           results['teachers_data'], results['students_data'],
                           results['json_saved'], results['excel_converted'], 
                           results['drive_uploaded']])
        total_steps = 7
        
        print(f"\nüéØ T·ªîNG K·∫æT: {success_count}/{total_steps} b∆∞·ªõc th√†nh c√¥ng")
    
    def _save_teachers_data(self, teachers_list, total_count):
        """L∆∞u d·ªØ li·ªáu gi√°o vi√™n v√†o file JSON"""
        try:
            
            teachers_data = {
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'data_type': 'teachers',
                'total_count': total_count,
                'retrieved_count': len(teachers_list),
                'teachers': teachers_list
            }
            
            filename = f"teachers_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            filepath = f"data/output/{filename}"
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(teachers_data, f, ensure_ascii=False, indent=2)
            
            print_status(f"‚úÖ ƒê√£ l∆∞u d·ªØ li·ªáu gi√°o vi√™n v√†o: {filepath}", "success")
            print(f"   üë®‚Äçüè´ S·ªë gi√°o vi√™n: {len(teachers_list)}/{total_count}")
            
        except Exception as e:
            print_status(f"‚ö†Ô∏è L·ªói l∆∞u d·ªØ li·ªáu gi√°o vi√™n: {e}", "warning")
    
    def _save_students_data(self, students_list, total_count):
        """L∆∞u d·ªØ li·ªáu h·ªçc sinh v√†o file JSON"""
        try:
            
            students_data = {
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'data_type': 'students',
                'total_count': total_count,
                'retrieved_count': len(students_list),
                'students': students_list
            }
            
            filename = f"students_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            filepath = f"data/output/{filename}"
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(students_data, f, ensure_ascii=False, indent=2)
            
            print_status(f"‚úÖ ƒê√£ l∆∞u d·ªØ li·ªáu h·ªçc sinh v√†o: {filepath}", "success")
            print(f"   üë®‚Äçüéì S·ªë h·ªçc sinh: {len(students_list)}/{total_count}")
            
        except Exception as e:
            print_status(f"‚ö†Ô∏è L·ªói l∆∞u d·ªØ li·ªáu h·ªçc sinh: {e}", "warning")

    def _save_unified_workflow_data(self, workflow_results, teachers_result=None, students_result=None, comparison_results=None, admin_password=None, workflow_type="case_1"):
        """
        L∆∞u t·∫•t c·∫£ d·ªØ li·ªáu workflow v√†o 1 file JSON t·ªïng h·ª£p
        
        Args:
            workflow_results: K·∫øt qu·∫£ workflow t·ªïng qu√°t
            teachers_result: K·∫øt qu·∫£ API gi√°o vi√™n (n·∫øu c√≥)
            students_result: K·∫øt qu·∫£ API h·ªçc sinh (n·∫øu c√≥) 
            comparison_results: K·∫øt qu·∫£ so s√°nh case 2 (n·∫øu c√≥)
            admin_password: M·∫≠t kh·∫©u admin (n·∫øu c√≥)
            workflow_type: "case_1" ho·∫∑c "case_2"
            
        Returns:
            str: ƒê∆∞·ªùng d·∫´n file JSON ƒë√£ l∆∞u
        """
        try:
            school_name = workflow_results['school_info'].get('name', 'Unknown')
            safe_school_name = "".join(c for c in school_name if c.isalnum() or c in (' ', '-', '_')).rstrip()
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # T·∫°o c·∫•u tr√∫c JSON th·ªëng nh·∫•t
            unified_data = {
                # === METADATA ===
                'metadata': {
                    'workflow_type': workflow_type,
                    'timestamp': timestamp,
                    'processed_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'version': '1.0'
                },
                
                # === SCHOOL INFO ===
                'school_info': {
                    'name': workflow_results['school_info'].get('name'),
                    'admin_email': workflow_results['school_info'].get('admin'),
                    'drive_link': workflow_results['school_info'].get('drive_link'),
                    'admin_password': admin_password  # C√≥ th·ªÉ None
                },
                
                # === WORKFLOW STATUS ===
                'workflow_status': {
                    'sheets_extraction': workflow_results.get('sheets_extraction', False),
                    'api_login': workflow_results.get('api_login', False),
                    'teachers_data': workflow_results.get('teachers_data', False),
                    'students_data': workflow_results.get('students_data', False),
                    'import_file_downloaded': workflow_results.get('import_file_downloaded', False),
                    'data_comparison': workflow_results.get('data_comparison', False),
                    'json_saved': True,  # Always true khi method n√†y ch·∫°y
                    'excel_converted': workflow_results.get('excel_converted', False),
                    'drive_uploaded': workflow_results.get('drive_uploaded', False)
                },
                
                # === DATA SUMMARY ===
                'data_summary': workflow_results.get('data_summary', {}),
                
                # === HT/HP INFO (n·∫øu c√≥) ===
                'ht_hp_info': workflow_results.get('ht_hp_info', {}),
                
                # === TEACHERS DATA ===
                'teachers': self._extract_teachers_data_for_unified(teachers_result),
                
                # === STUDENTS DATA ===
                'students': self._extract_students_data_for_unified(students_result)
            }
            
            # === CASE 2 SPECIFIC DATA ===
            if workflow_type == "case_2" and comparison_results:
                unified_data['comparison_results'] = {
                    'method': comparison_results.get('comparison_method', 'name_and_birthdate'),
                    'import_file_info': workflow_results.get('import_file_info', {}),
                    'import_teachers_count': comparison_results.get('import_teachers_count', 0),
                    'import_students_count': comparison_results.get('import_students_count', 0),
                    'teachers_matched': comparison_results.get('teachers_matched', 0),
                    'students_matched': comparison_results.get('students_matched', 0),
                    'teachers_filtered': comparison_results.get('teachers_filtered', []),
                    'students_filtered': comparison_results.get('students_filtered', []),
                    'has_students_in_system': workflow_results.get('data_summary', {}).get('has_students_in_system', True)
                }
                
                # Override teachers/students v·ªõi filtered data cho case 2
                if comparison_results.get('teachers_filtered'):
                    unified_data['teachers']['data'] = comparison_results.get('teachers_filtered', [])
                    unified_data['teachers']['retrieved_count'] = len(comparison_results.get('teachers_filtered', []))
                
                # Ch·ªâ override students data n·∫øu h·ªá th·ªëng c√≥ h·ªçc sinh
                has_students_in_system = workflow_results.get('data_summary', {}).get('has_students_in_system', True)
                if has_students_in_system and comparison_results.get('students_filtered'):
                    unified_data['students']['data'] = comparison_results.get('students_filtered', [])
                    unified_data['students']['retrieved_count'] = len(comparison_results.get('students_filtered', []))
                elif not has_students_in_system:
                    # N·∫øu h·ªá th·ªëng kh√¥ng c√≥ h·ªçc sinh, ƒë√°nh d·∫•u ƒë·ªÉ converter bi·∫øt
                    unified_data['students']['data'] = []
                    unified_data['students']['retrieved_count'] = 0
                    unified_data['students']['system_has_students'] = False
            
            # === SAVE TO FILE ===
            filename = f"unified_workflow_{workflow_type}_{safe_school_name}_{timestamp}.json"
            filepath = f"data/output/{filename}"
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(unified_data, f, ensure_ascii=False, indent=2)
            
            print_status(f"‚úÖ ƒê√£ l∆∞u d·ªØ li·ªáu t·ªïng h·ª£p v√†o: {filepath}", "success")
            
            # In th·ªëng k√™ nhanh
            teachers_count = unified_data['teachers']['retrieved_count']
            students_count = unified_data['students']['retrieved_count']
            print(f"   üìä T·ªïng: {teachers_count} gi√°o vi√™n, {students_count} h·ªçc sinh")
            
            if workflow_type == "case_2" and comparison_results:
                print(f"   üîç So s√°nh: {comparison_results.get('teachers_matched', 0)} GV, {comparison_results.get('students_matched', 0)} HS")
            
            return filepath
            
        except Exception as e:
            print_status(f"‚ö†Ô∏è L·ªói l∆∞u d·ªØ li·ªáu unified workflow: {e}", "warning")
            import traceback
            traceback.print_exc()
            return None
    
    def _extract_teachers_data_for_unified(self, teachers_result):
        """Tr√≠ch xu·∫•t v√† chu·∫©n h√≥a d·ªØ li·ªáu teachers cho unified workflow"""
        if not teachers_result:
            return {
                'success': False,
                'total_count': 0,
                'retrieved_count': 0,
                'data': []
            }
        
        success = teachers_result.get('success', False)
        if not success:
            return {
                'success': False,
                'total_count': 0,
                'retrieved_count': 0,
                'data': []
            }
        
        # X·ª≠ l√Ω c·∫•u tr√∫c d·ªØ li·ªáu l·ªìng nhau t·ª´ API
        api_data = teachers_result.get('data', {})
        if isinstance(api_data, dict) and 'data' in api_data:
            # C·∫•u tr√∫c: {success: true, data: {currentCount: 65, data: [...]}}
            teachers_list = api_data.get('data', [])
            total_count = api_data.get('currentCount', len(teachers_list))
        elif isinstance(api_data, list):
            # C·∫•u tr√∫c: {success: true, data: [...]}
            teachers_list = api_data
            total_count = len(teachers_list)
        else:
            teachers_list = []
            total_count = 0
        
        return {
            'success': success,
            'total_count': total_count,
            'retrieved_count': len(teachers_list),
            'data': teachers_list
        }
    
    def _extract_students_data_for_unified(self, students_result):
        """Tr√≠ch xu·∫•t v√† chu·∫©n h√≥a d·ªØ li·ªáu students cho unified workflow"""
        if not students_result:
            return {
                'success': False,
                'total_count': 0,
                'retrieved_count': 0,
                'data': []
            }
        
        success = students_result.get('success', False)
        if not success:
            return {
                'success': False,
                'total_count': 0,
                'retrieved_count': 0,
                'data': []
            }
        
        # X·ª≠ l√Ω c·∫•u tr√∫c d·ªØ li·ªáu l·ªìng nhau t·ª´ API
        api_data = students_result.get('data', {})
        if isinstance(api_data, dict) and 'data' in api_data:
            # C·∫•u tr√∫c: {success: true, data: {currentCount: 845, data: [...]}}
            students_list = api_data.get('data', [])
            total_count = api_data.get('currentCount', len(students_list))
        elif isinstance(api_data, list):
            # C·∫•u tr√∫c: {success: true, data: [...]}
            students_list = api_data
            total_count = len(students_list)
        else:
            students_list = []
            total_count = 0
        
        return {
            'success': success,
            'total_count': total_count,
            'retrieved_count': len(students_list),
            'data': students_list
        }
    
    def _download_import_file(self, school_name, drive_link, ui_mode=False):
        """T·∫£i file import t·ª´ Google Drive v·ªõi pattern 'import_*'"""
        try:
            # Kh·ªüi t·∫°o OAuth client
            oauth_client = GoogleOAuthDriveClient()
            
            if not oauth_client.is_authenticated():
                print_status("‚ùå OAuth ch∆∞a ƒë∆∞·ª£c setup", "error")
                return None
            
            # Extract folder ID
            folder_id = self._extract_drive_folder_id(drive_link)
            if not folder_id:
                print_status("‚ùå Kh√¥ng th·ªÉ extract folder ID t·ª´ drive link", "error")
                return None
            
            print(f"   üîç T√¨m file c√≥ pattern: import_*.xlsx")
            
            # T√¨m t·∫•t c·∫£ file b·∫Øt ƒë·∫ßu b·∫±ng "import_" trong Drive folder
            import_files = self._find_import_files_in_drive_folder(oauth_client, folder_id)
            
            if not import_files:
                print_status(f"‚ùå Kh√¥ng t√¨m th·∫•y file n√†o c√≥ pattern 'import_*.xlsx'", "error")
                return None
            
            # N·∫øu c√≥ nhi·ªÅu file, cho user ch·ªçn (ho·∫∑c auto-select n·∫øu UI mode)
            selected_file = None
            if len(import_files) == 1:
                selected_file = import_files[0]
                print(f"   ‚úÖ T√¨m th·∫•y file: {selected_file['name']}")
            else:
                print(f"\nüìã T√åM TH·∫§Y {len(import_files)} FILE IMPORT:")
                for i, file in enumerate(import_files, 1):
                    print(f"   {i}. {file['name']}")
                
                if ui_mode:
                    # Trong UI mode, t·ª± ƒë·ªông ch·ªçn file ƒë·∫ßu ti√™n
                    selected_file = import_files[0]
                    print(f"   üîÑ T·ª± ƒë·ªông ch·ªçn file ƒë·∫ßu ti√™n: {selected_file['name']}")
                else:
                    # Trong console mode, cho user ch·ªçn
                    try:
                        choice = get_user_input(f"Ch·ªçn file import (1-{len(import_files)})", required=True)
                        choice_idx = int(choice) - 1
                        if 0 <= choice_idx < len(import_files):
                            selected_file = import_files[choice_idx]
                        else:
                            print_status("L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá", "error")
                            return None
                    except (ValueError, TypeError):
                        print_status("L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá", "error")
                        return None
            
            if not selected_file:
                return None
            
            # T·∫£i file v·ªÅ local
            local_filename = selected_file['name']
            local_path = f"data/temp/{local_filename}"
            os.makedirs("data/temp", exist_ok=True)
            
            success = self._download_file_from_drive(oauth_client, selected_file['id'], local_path)
            
            if success:
                print_status(f"‚úÖ ƒê√£ t·∫£i file import: {local_filename}", "success")
                return local_path
            else:
                print_status("‚ùå L·ªói t·∫£i file import", "error")
                return None
                
        except ImportError:
            print_status("‚ùå OAuth module ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t", "error")
            return None
        except Exception as e:
            print_status(f"‚ùå L·ªói t·∫£i file import: {e}", "error")
            return None
    
    def _find_import_files_in_drive_folder(self, oauth_client, folder_id):
        """T√¨m t·∫•t c·∫£ file b·∫Øt ƒë·∫ßu b·∫±ng 'import_' trong Drive folder"""
        try:
            # T√¨m file v·ªõi pattern "import_" v√† ph·∫ßn m·ªü r·ªông .xlsx
            query = f"parents in '{folder_id}' and trashed=false and name contains 'import_' and (name contains '.xlsx' or name contains '.xls')"
            
            results = oauth_client.drive_service.files().list(
                q=query,
                spaces='drive',
                fields='files(id, name)',
                pageSize=100
            ).execute()
            
            files = results.get('files', [])
            
            # L·ªçc th√™m ƒë·ªÉ ch·ªâ l·∫•y file th·ª±c s·ª± b·∫Øt ƒë·∫ßu b·∫±ng "import_"
            import_files = []
            for file in files:
                filename = file['name'].lower()
                if filename.startswith('import_') and (filename.endswith('.xlsx') or filename.endswith('.xls')):
                    import_files.append(file)
            
            return import_files
                
        except Exception as e:
            print_status(f"‚ùå L·ªói t√¨m file import: {e}", "error")
            return []
    
    def _download_file_from_drive(self, oauth_client, file_id, local_path):
        """T·∫£i file t·ª´ Drive v·ªÅ local"""
        try:
            
            request = oauth_client.drive_service.files().get_media(fileId=file_id)
            
            with open(local_path, 'wb') as f:
                downloader = MediaIoBaseDownload(f, request)
                done = False
                while done is False:
                    status, done = downloader.next_chunk()
            
            return True
            
        except Exception as e:
            print_status(f"‚ùå L·ªói download file: {e}", "error")
            return False
    
    def _compare_and_filter_data(self, teachers_result, students_result, import_file_path):
        """So s√°nh v√† l·ªçc d·ªØ li·ªáu d·ª±a tr√™n file import theo H·ªç t√™n v√† Ng√†y sinh"""
        try:
            
            # ƒê·ªçc file import v·ªõi t·∫•t c·∫£ sheets
            print("   üìÇ ƒê·ªçc file import...")
            excel_file = pd.ExcelFile(import_file_path)
            
            comparison_results = {
                'teachers_filtered': [],
                'students_filtered': [],
                'import_teachers_count': 0,
                'import_students_count': 0,
                'teachers_matched': 0,
                'students_matched': 0,
                'comparison_method': 'name_and_birthdate'
            }
            
            # X·ª≠ l√Ω sheet Teachers n·∫øu c√≥
            teachers_import_data = []
            export_all_teachers = False  # Flag ƒë·ªÉ xu·∫•t t·∫•t c·∫£ gi√°o vi√™n
            
            if 'Teachers' in excel_file.sheet_names:
                teachers_df = pd.read_excel(import_file_path, sheet_name='Teachers')
                print(f"   üë®‚Äçüè´ Sheet Teachers: {len(teachers_df)} rows")
                
                # Chu·∫©n h√≥a format ng√†y th√°ng trong DataFrame tr∆∞·ªõc khi x·ª≠ l√Ω
                teachers_df = self._standardize_import_date_formats(teachers_df)
                
                # T√¨m c·ªôt h·ªç t√™n, ng√†y sinh v√† t√™n ƒëƒÉng nh·∫≠p
                name_col = self._find_column_by_keywords(teachers_df.columns, ['h·ªç t√™n', 't√™n', 'name', 'gi√°o vi√™n'])
                birth_col = self._find_column_by_keywords(teachers_df.columns, ['ng√†y sinh', 'sinh', 'birth', 'date'])
                username_col = self._find_column_by_keywords(teachers_df.columns, ['t√™n ƒëƒÉng nh·∫≠p', 'username', 'user name', 'login', 'account'])
                
                print(f"      üìã C·ªôt t√™n: '{name_col}', C·ªôt ng√†y sinh: '{birth_col}', C·ªôt t√™n ƒëƒÉng nh·∫≠p: '{username_col}'")
                
                if name_col:  # Ch·ªâ c·∫ßn c√≥ c·ªôt t√™n l√† ƒë·ªß ƒë·ªÉ b·∫Øt ƒë·∫ßu
                    # Ki·ªÉm tra xem c√≥ gi√°o vi√™n n√†o t√™n GVCN kh√¥ng (s·ª≠ d·ª•ng pattern matching)
                    gvcn_found = False
                    
                    # Ki·ªÉm tra xem c√≥ gi√°o vi√™n n√†o t√™n GVCN kh√¥ng (s·ª≠ d·ª•ng pattern matching)
                    gvcn_found = False
                    for _, row in teachers_df.iterrows():
                        name = str(row[name_col]).strip() if pd.notna(row[name_col]) else ""
                        if name and self._is_gvcn_name_in_import(name):
                            gvcn_found = True
                            print(f"      üîç T√¨m th·∫•y GVCN pattern: '{name}'")
                            break
                    
                    if gvcn_found:
                        export_all_teachers = True
                        print(f"      üîç T√¨m th·∫•y 'GVCN' ‚Üí S·∫Ω xu·∫•t T·∫§T C·∫¢ gi√°o vi√™n t·ª´ OnLuyen")
                    else:
                        print(f"      üîç Kh√¥ng c√≥ 'GVCN' ‚Üí Ch·ªâ xu·∫•t gi√°o vi√™n c√≥ trong import")
                        
                        # Parse danh s√°ch gi√°o vi√™n t·ª´ import ƒë·ªÉ so s√°nh
                        print(f"      üîç Parsing teachers from import file...")
                        parsed_count = 0
                        skipped_gvcn_count = 0
                        
                        for idx, row in teachers_df.iterrows():
                            name = str(row[name_col]).strip() if pd.notna(row[name_col]) else ""
                            birth = str(row[birth_col]).strip() if pd.notna(row[birth_col]) and birth_col else ""
                            username = str(row[username_col]).strip() if pd.notna(row[username_col]) and username_col else ""
                            
                            if name:  # Ch·ªâ c·∫ßn c√≥ t√™n l√† ƒë·ªß
                                if self._is_gvcn_name_in_import(name):
                                    skipped_gvcn_count += 1
                                    print(f"         üö´ Skipping GVCN: '{name}'")
                                else:
                                    normalized_name = self._normalize_name(name)
                                    normalized_birth = self._normalize_date(birth) if birth else ""
                                    normalized_username = username.lower().strip() if username else ""
                                    
                                    teachers_import_data.append({
                                        'name': normalized_name,
                                        'birthdate': normalized_birth,
                                        'username': normalized_username,
                                        'raw_name': name,
                                        'raw_birthdate': birth,
                                        'raw_username': username
                                    })
                                    parsed_count += 1
                                    
                                    # Debug first few teachers
                                    if parsed_count <= 5:
                                        print(f"         ‚úÖ Parsed teacher {parsed_count}: '{name}' | Birth: '{birth}' | Username: '{username}'")
                                        print(f"            ‚Üí Normalized: '{normalized_name}' | '{normalized_birth}' | '{normalized_username}'")
                        
                        print(f"      üìä Parsing summary: {parsed_count} teachers parsed, {skipped_gvcn_count} GVCN skipped")
                
                comparison_results['import_teachers_count'] = len(teachers_import_data)
                comparison_results['export_all_teachers'] = export_all_teachers
                
                if export_all_teachers:
                    print(f"      ‚úÖ Ch·∫ø ƒë·ªô xu·∫•t t·∫•t c·∫£ gi√°o vi√™n (c√≥ GVCN)")
                else:
                    print(f"      ‚úÖ ƒê√£ parse {len(teachers_import_data)} gi√°o vi√™n t·ª´ import")
            
            # X·ª≠ l√Ω sheet Students n·∫øu c√≥
            students_import_data = []
            if 'Students' in excel_file.sheet_names:
                students_df = pd.read_excel(import_file_path, sheet_name='Students')
                print(f"   üë®‚Äçüéì Sheet Students: {len(students_df)} rows")
                
                # Chu·∫©n h√≥a format ng√†y th√°ng trong DataFrame tr∆∞·ªõc khi x·ª≠ l√Ω
                students_df = self._standardize_import_date_formats(students_df)
                
                # T√¨m c·ªôt h·ªç t√™n v√† ng√†y sinh
                name_col = self._find_column_by_keywords(students_df.columns, ['h·ªç t√™n', 'h·ªç v√† t√™n', 'fullname', 't√™n h·ªçc sinh'])
                birth_col = self._find_column_by_keywords(students_df.columns, ['ng√†y sinh', 'sinh', 'birth', 'date'])
                
                if name_col and birth_col:
                    print(f"      ÔøΩ C·ªôt t√™n: '{name_col}', C·ªôt ng√†y sinh: '{birth_col}'")
                    
                    for _, row in students_df.iterrows():
                        name = str(row[name_col]).strip() if pd.notna(row[name_col]) else ""
                        birth = str(row[birth_col]).strip() if pd.notna(row[birth_col]) else ""
                        
                        if name and birth:
                            normalized_name = self._normalize_name(name)
                            normalized_birth = self._normalize_date(birth)
                            
                            students_import_data.append({
                                'name': normalized_name,
                                'birthdate': normalized_birth,
                                'raw_name': name,
                                'raw_birthdate': birth
                            })
                
                comparison_results['import_students_count'] = len(students_import_data)
                print(f"      ‚úÖ ƒê√£ parse {len(students_import_data)} h·ªçc sinh t·ª´ import")
            
            # So s√°nh v√† l·ªçc gi√°o vi√™n
            if teachers_result and teachers_result.get('success'):
                print("   üîç X·ª≠ l√Ω danh s√°ch gi√°o vi√™n...")
                teachers_data = teachers_result['data']
                
                if isinstance(teachers_data, dict) and 'data' in teachers_data:
                    onluyen_teachers = teachers_data['data']
                    
                    if comparison_results.get('export_all_teachers', False):
                        # Xu·∫•t t·∫•t c·∫£ gi√°o vi√™n t·ª´ OnLuyen (v√¨ c√≥ GVCN) nh∆∞ng lo·∫°i b·ªè nh·ªØng gi√°o vi√™n t√™n "GVCN"
                        filtered_teachers = []
                        for teacher in onluyen_teachers:
                            # S·ª≠ d·ª•ng helper function ƒë·ªÉ ki·ªÉm tra GVCN
                            if not self._is_gvcn_teacher(teacher):
                                filtered_teachers.append(teacher)
                        
                        comparison_results['teachers_filtered'] = filtered_teachers
                        comparison_results['teachers_matched'] = len(filtered_teachers)
                        original_count = len(onluyen_teachers)
                        excluded_count = original_count - len(filtered_teachers)
                        print(f"      ‚úÖ Xu·∫•t {len(filtered_teachers)}/{original_count} gi√°o vi√™n (lo·∫°i b·ªè {excluded_count} gi√°o vi√™n GVCN)")
                        
                    elif teachers_import_data:
                        # Ch·ªâ xu·∫•t gi√°o vi√™n kh·ªõp v·ªõi import - S·ª≠ d·ª•ng enhanced matching logic
                        print(f"      ÔøΩ OnLuyen c√≥ {len(onluyen_teachers)} gi√°o vi√™n")
                        print(f"      üìã Import c√≥ {len(teachers_import_data)} gi√°o vi√™n")
                        
                        # S·ª≠ d·ª•ng enhanced matching logic
                        matched_teachers, matched_count = self._match_with_enhanced_logic(
                            onluyen_teachers, teachers_import_data, "teachers"
                        )
                        
                        comparison_results['teachers_filtered'] = matched_teachers
                        comparison_results['teachers_matched'] = matched_count
                        print(f"      ‚úÖ Kh·ªõp {matched_count}/{len(teachers_import_data)} gi√°o vi√™n")
                        
                    else:
                        print(f"      ‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu gi√°o vi√™n import ƒë·ªÉ so s√°nh")
            
            # So s√°nh v√† l·ªçc h·ªçc sinh
            if students_result and students_result.get('success'):
                print("   üîç X·ª≠ l√Ω danh s√°ch h·ªçc sinh...")
                students_data = students_result['data']
                
                if isinstance(students_data, dict) and 'data' in students_data:
                    onluyen_students = students_data['data']
                    print(f"      üìä OnLuyen c√≥ {len(onluyen_students)} h·ªçc sinh")
                    
                    if students_import_data:
                        print("   üîç So s√°nh v·ªõi file import...")
                        
                        # S·ª≠ d·ª•ng enhanced matching logic
                        matched_students, matched_count = self._match_with_enhanced_logic(
                            onluyen_students, students_import_data, "students"
                        )
                        
                        comparison_results['students_filtered'] = matched_students
                        comparison_results['students_matched'] = matched_count
                        print(f"      ‚úÖ Kh·ªõp {matched_count}/{len(students_import_data)} h·ªçc sinh")
                    
                    else:
                        # N·∫øu kh√¥ng c√≥ import data, xu·∫•t t·∫•t c·∫£ h·ªçc sinh
                        print("      ‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu h·ªçc sinh import - Xu·∫•t t·∫•t c·∫£ h·ªçc sinh OnLuyen")
                        comparison_results['students_filtered'] = onluyen_students
                        comparison_results['students_matched'] = len(onluyen_students)
                else:
                    print("      ‚ùå ƒê·ªãnh d·∫°ng d·ªØ li·ªáu h·ªçc sinh OnLuyen kh√¥ng ƒë√∫ng")
            else:
                print("      ‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu h·ªçc sinh OnLuyen")
            
            return comparison_results
            
        except Exception as e:
            print_status(f"‚ùå L·ªói so s√°nh d·ªØ li·ªáu: {e}", "error")
            return None
    
    def _save_unmatched_log(self, unmatched_onluyen, unmatched_import):
        """L∆∞u log chi ti·∫øt c√°c tr∆∞·ªùng h·ª£p kh√¥ng kh·ªõp v√†o file"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            log_filename = f"unmatched_students_log_{timestamp}.json"
            log_filepath = f"data/output/{log_filename}"
            
            log_data = {
                'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'summary': {
                    'unmatched_onluyen_count': len(unmatched_onluyen),
                    'unmatched_import_count': len(unmatched_import),
                    'total_unmatched': len(unmatched_onluyen) + len(unmatched_import)
                },
                'unmatched_onluyen_students': unmatched_onluyen,
                'unmatched_import_students': unmatched_import,
                'analysis': {
                    'common_issues': [
                        'Sai format ng√†y th√°ng (DD/MM/YYYY vs MM/DD/YYYY)',
                        'Kh√°c bi·ªát trong c√°ch vi·∫øt t√™n (d·∫•u, kho·∫£ng tr·∫Øng)',
                        'Thi·∫øu ho·∫∑c th·ª´a th√¥ng tin trong m·ªôt trong hai ngu·ªìn',
                        'L·ªói nh·∫≠p li·ªáu t·ª´ tr∆∞·ªùng h·ªçc'
                    ],
                    'recommendations': [
                        'Ki·ªÉm tra format ng√†y th√°ng trong file import',
                        'So s√°nh t√™n h·ªçc sinh v·ªõi ƒë·ªô t∆∞∆°ng ƒë·ªìng cao',
                        'X√°c minh v·ªõi tr∆∞·ªùng h·ªçc v·ªÅ th√¥ng tin ch√≠nh x√°c',
                        'C√¢n nh·∫Øc s·ª≠ d·ª•ng debug functions ƒë·ªÉ ph√¢n t√≠ch chi ti·∫øt'
                    ]
                }
            }
            
            with open(log_filepath, 'w', encoding='utf-8') as f:
                json.dump(log_data, f, ensure_ascii=False, indent=2)
            
            print(f"      üìÑ ƒê√£ l∆∞u unmatched log: {log_filepath}")
            
        except Exception as e:
            print(f"      ‚ö†Ô∏è L·ªói l∆∞u unmatched log: {e}")

    def _find_column_by_keywords(self, columns, keywords):
        """T√¨m c·ªôt theo t·ª´ kh√≥a"""
        for col in columns:
            col_lower = str(col).lower()
            for keyword in keywords:
                if keyword in col_lower:
                    return col
        return None
    
    def _is_date_create_within_days(self, date_create_str, days=2):
        """Ki·ªÉm tra dateCreate c√≥ trong v√≤ng N ng√†y t·ª´ h√¥m nay"""
        if not date_create_str:
            return False
        
        try:
            # Parse ISO datetime: "2022-03-07T04:13:38.46Z"
            if 'T' in date_create_str:
                date_create_str = date_create_str.split('T')[0]  # L·∫•y ph·∫ßn date
            
            # Parse date: "2022-03-07"
            date_create = datetime.strptime(date_create_str, '%Y-%m-%d')
            current_date = datetime.now()
            
            # T√≠nh s·ªë ng√†y ch√™nh l·ªách
            delta = current_date - date_create
            
            return 0 <= delta.days <= days
        except Exception as e:
            return False
    
    def _find_best_date_create_match(self, candidates_with_same_name, days=30):
        """
        T·ª´ danh s√°ch candidates c√≥ c√πng t√™n, t√¨m candidate c√≥ dateCreate m·ªõi nh·∫•t trong v√≤ng N ng√†y
        
        Args:
            candidates_with_same_name: List c√°c OnLuyen records c√≥ c√πng t√™n
            days: S·ªë ng√†y t·ª´ hi·ªán t·∫°i ƒë·ªÉ check dateCreate (default 30 ng√†y)
            
        Returns:
            dict: Best match candidate ho·∫∑c None
        """
        valid_candidates = []
        
        print(f"            üîç Checking dateCreate within {days} days...")
        
        for candidate in candidates_with_same_name:
            date_create = candidate.get('dateCreate', '')
            if self._is_date_create_within_days(date_create, days):
                try:
                    # Parse ƒë·ªÉ so s√°nh
                    if 'T' in date_create:
                        date_create_clean = date_create.split('T')[0]
                    else:
                        date_create_clean = date_create
                    
                    parsed_date = datetime.strptime(date_create_clean, '%Y-%m-%d')
                    valid_candidates.append((candidate, parsed_date))
                    print(f"            ‚úÖ Valid candidate: dateCreate = {date_create}")
                except:
                    print(f"            ‚ùå Invalid dateCreate format: {date_create}")
                    continue
            else:
                print(f"            ‚ùå Outside {days} days range: {date_create}")
        
        if not valid_candidates:
            print(f"            ‚ùå No valid candidates within {days} days")
            return None
        
        # S·∫Øp x·∫øp theo dateCreate m·ªõi nh·∫•t (descending)
        valid_candidates.sort(key=lambda x: x[1], reverse=True)
        best_candidate = valid_candidates[0][0]
        
        print(f"            ‚úÖ Best match: dateCreate = {best_candidate.get('dateCreate', '')}")
        return best_candidate
        
        if not valid_candidates:
            return None
        
        # S·∫Øp x·∫øp theo dateCreate m·ªõi nh·∫•t (descending)
        valid_candidates.sort(key=lambda x: x[1], reverse=True)
        
        return valid_candidates[0][0]  # Tr·∫£ v·ªÅ candidate c√≥ dateCreate m·ªõi nh·∫•t
    
    def _match_with_enhanced_logic(self, onluyen_records, import_data, record_type="students"):
        """
        So s√°nh v·ªõi logic n√¢ng cao 3 m·ª©c ∆∞u ti√™n:
        1. ∆Øu ti√™n cao nh·∫•t: T√™n + Ng√†y sinh (exact match)
        2. ∆Øu ti√™n cao: T√™n + T√™n ƒëƒÉng nh·∫≠p (khi c√≥ username)
        3. ∆Øu ti√™n th·∫•p: Ch·ªâ T√™n (d√πng dateCreate ƒë·ªÉ ch·ªçn ng∆∞·ªùi m·ªõi nh·∫•t n·∫øu c√≥ nhi·ªÅu ng∆∞·ªùi c√πng t√™n)
        
        Logic cho Method 3:
        - N·∫øu ch·ªâ c√≥ 1 ng∆∞·ªùi c√πng t√™n: match lu√¥n
        - N·∫øu c√≥ nhi·ªÅu ng∆∞·ªùi c√πng t√™n: ch·ªçn ng∆∞·ªùi c√≥ dateCreate m·ªõi nh·∫•t trong 30 ng√†y
        - N·∫øu kh√¥ng ai c√≥ dateCreate trong 30 ng√†y: fallback ch·ªçn ng∆∞·ªùi ƒë·∫ßu ti√™n
        
        Args:
            onluyen_records: List records t·ª´ OnLuyen API
        Args:
            onluyen_records: List records t·ª´ OnLuyen API
            import_data: List records t·ª´ file import ƒë√£ parse
            record_type: "students" ho·∫∑c "teachers"
            
        Returns:
            tuple: (matched_records, matched_count)
        """
        matched_records = []
        matched_count = 0
        
        # T·∫°o lookup dictionaries
        # 1. Name + Birthdate exact match (∆∞u ti√™n cao nh·∫•t)
        name_birth_lookup = {}
        for item in import_data:
            if item['name'] and item.get('birthdate'):
                key = (item['name'], item['birthdate'])
                name_birth_lookup[key] = item
        
        # 2. Name + Username match (∆∞u ti√™n cao) - bao g·ªìm c·∫£ c√≥ v√† kh√¥ng c√≥ birthdate
        name_username_lookup = {}
        for item in import_data:
            if item['name'] and item.get('username'):
                key = (item['name'], item['username'])
                name_username_lookup[key] = item
        
        # 3. Name-only lookup cho fallback (t·∫•t c·∫£ items c√≥ t√™n)
        name_only_lookup = {}
        for item in import_data:
            if item['name']:
                name = item['name']
                if name not in name_only_lookup:
                    name_only_lookup[name] = []
                name_only_lookup[name].append(item)
        
        print(f"      üîç Enhanced matching for {record_type}:")
        print(f"         - Name+Birth lookup: {len(name_birth_lookup)} items")
        print(f"         - Name+Username lookup: {len(name_username_lookup)} items")
        print(f"         - Name-only lookup: {len(name_only_lookup)} items")
        
        # Group OnLuyen records by name for efficient lookup
        onluyen_by_name = {}
        for record in onluyen_records:
            if record_type == "students":
                user_info = record.get('userInfo', {})
                record_name = self._normalize_name(
                    record.get('fullName', '') or user_info.get('displayName', '')
                )
            else:  # teachers
                record_info = record.get('teacherInfo', {})
                record_name = self._normalize_name(
                    record.get('fullName', '') or record_info.get('displayName', '')
                )
            
            if record_name:
                if record_name not in onluyen_by_name:
                    onluyen_by_name[record_name] = []
                onluyen_by_name[record_name].append(record)
        
        # Process each OnLuyen record
        for record in onluyen_records:
            # Skip GVCN teachers
            if record_type == "teachers" and self._is_gvcn_teacher(record):
                continue
            
            # Extract name, birthdate and username
            if record_type == "students":
                user_info = record.get('userInfo', {})
                record_name = self._normalize_name(
                    record.get('fullName', '') or user_info.get('displayName', '')
                )
                record_birth = self._normalize_date(
                    record.get('birthDate', '') or user_info.get('userBirthday', '')
                )
                record_username = (record.get('account', '') or user_info.get('account', '')).lower().strip()
            else:  # teachers
                record_info = record.get('teacherInfo', {})
                record_name = self._normalize_name(
                    record.get('fullName', '') or record_info.get('displayName', '')
                )
                record_birth = self._normalize_date(record.get('birthDate', ''))
                record_username = record.get('account', '').lower().strip()
            
            if not record_name:
                continue
            
            matched = False
            
            # Method 1: Exact name + birthdate match (∆∞u ti√™n cao nh·∫•t)
            if record_name and record_birth:
                key = (record_name, record_birth)
                if key in name_birth_lookup:
                    matched_records.append(record)
                    matched_count += 1
                    matched = True
                    print(f"         ‚úÖ Name+Birth match: '{record_name}' | '{record_birth}'")
                    continue
            
            # Method 2: Name + Username match (∆∞u ti√™n cao)
            if not matched and record_name and record_username:
                key = (record_name, record_username)
                if key in name_username_lookup:
                    matched_records.append(record)
                    matched_count += 1
                    matched = True
                    print(f"         ‚úÖ Name+Username match: '{record_name}' | '{record_username}'")
                    continue
            
            # Method 3: Name-only match v·ªõi dateCreate logic (∆∞u ti√™n th·∫•p nh·∫•t)
            if not matched and record_name in name_only_lookup:
                # L·∫•y t·∫•t c·∫£ OnLuyen records c√≥ c√πng t√™n
                candidates_with_same_name = onluyen_by_name.get(record_name, [])
                
                if len(candidates_with_same_name) == 1:
                    # Ch·ªâ c√≥ 1 candidate, match lu√¥n
                    matched_records.append(record)
                    matched_count += 1
                    matched = True
                    print(f"         ‚úÖ Name-only match (single): '{record_name}'")
                
                elif len(candidates_with_same_name) > 1:
                    # C√≥ nhi·ªÅu candidates c√πng t√™n, ch·ªçn theo dateCreate m·ªõi nh·∫•t trong v√≤ng 30 ng√†y
                    print(f"         üîç Found {len(candidates_with_same_name)} candidates with name '{record_name}', checking dateCreate...")
                    
                    # Debug: hi·ªÉn th·ªã dateCreate c·ªßa c√°c candidates
                    for i, candidate in enumerate(candidates_with_same_name, 1):
                        date_create = candidate.get('dateCreate', 'No dateCreate')
                        print(f"            Candidate {i}: dateCreate = {date_create}")
                    
                    best_match = self._find_best_date_create_match(candidates_with_same_name, 30)
                    
                    if best_match and best_match == record:  # Ch·ªâ add n·∫øu record hi·ªán t·∫°i l√† best match
                        matched_records.append(best_match)
                        matched_count += 1
                        matched = True
                        print(f"         ‚úÖ Name-only match (best dateCreate of {len(candidates_with_same_name)}): '{record_name}' | dateCreate: {best_match.get('dateCreate', '')}")
                    elif not best_match:
                        # Kh√¥ng c√≥ ai trong v√≤ng 30 ng√†y, l·∫•y ng∆∞·ªùi ƒë·∫ßu ti√™n (fallback)
                        if record == candidates_with_same_name[0]:
                            matched_records.append(record)
                            matched_count += 1
                            matched = True
                            print(f"         ‚úÖ Name-only match (fallback first of {len(candidates_with_same_name)}): '{record_name}'")
            
            if not matched:
                print(f"         ‚ùå No match found: '{record_name}'")
        
        return matched_records, matched_count
    
    def _analyze_date_format_in_import(self, df, column_name):
        """Ph√¢n t√≠ch format ng√†y th√°ng th·ª±c t·∫ø trong DataFrame c·ªôt c·ª• th·ªÉ"""
        
        try:
            # Collect date samples t·ª´ c·ªôt ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh
            date_samples = []
            
            if column_name not in df.columns:
                print(f"   ‚ùå Kh√¥ng t√¨m th·∫•y c·ªôt '{column_name}' trong DataFrame")
                return None
            
            print(f"   üîç Analyzing date format in column '{column_name}'...")
            
            # L·∫•y t·ªëi ƒëa 20 samples c√≥ d·ªØ li·ªáu
            sample_count = 0
            for _, row in df.iterrows():
                if sample_count >= 20:
                    break
                    
                date_value = row[column_name]
                if pd.notna(date_value):
                    date_str = str(date_value).strip()
                    if date_str and date_str not in ['', 'nan', 'NaN']:
                        date_samples.append(date_str)
                        sample_count += 1
            
            if not date_samples:
                print(f"   ‚ùå Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ng√†y h·ª£p l·ªá trong c·ªôt '{column_name}'")
                return None
            
            print(f"   üìä Collected {len(date_samples)} date samples for analysis")
            print(f"   üìù Sample dates: {date_samples[:5]}...")  # Show first 5 samples
            
            # Analyze patterns
            format_scores = {
                'DD/MM/YYYY': 0,
                'MM/DD/YYYY': 0, 
                'YYYY-MM-DD': 0,
                'Excel_DateTime': 0
            }
            
            total_analyzed = 0
            
            for date_str in date_samples:
                total_analyzed += 1
                
                # Check for Excel DateTime format (has timestamp)
                if ' ' in date_str and ':' in date_str:
                    format_scores['Excel_DateTime'] += 1
                    continue
                
                # Parse DD/MM/YYYY or MM/DD/YYYY patterns
                match = re.match(r'(\d{1,2})[/\-](\d{1,2})[/\-](\d{4})', date_str)
                if match:
                    first_num = int(match.group(1))
                    second_num = int(match.group(2))
                    
                    # Disambiguation logic
                    if first_num > 12:
                        # First number > 12, must be day -> DD/MM/YYYY
                        format_scores['DD/MM/YYYY'] += 2  # Higher weight for clear indication
                    elif second_num > 12:
                        # Second number > 12, must be day -> MM/DD/YYYY  
                        format_scores['MM/DD/YYYY'] += 2
                    else:
                        # Both <= 12, ambiguous - give small weight to both
                        format_scores['DD/MM/YYYY'] += 1
                        format_scores['MM/DD/YYYY'] += 1
                    continue
                
                # Check for YYYY-MM-DD format
                if re.match(r'(\d{4})[/\-](\d{1,2})[/\-](\d{1,2})', date_str):
                    format_scores['YYYY-MM-DD'] += 1
                    continue
            
            # Calculate percentages and find most likely format
            if total_analyzed == 0:
                return None
                
            format_percentages = {}
            for fmt, score in format_scores.items():
                format_percentages[fmt] = round((score / total_analyzed) * 100, 1)
            
            # Find format with highest score
            most_likely_format = max(format_scores.keys(), key=lambda k: format_scores[k])
            confidence_score = format_percentages[most_likely_format]
            
            result = {
                'most_likely_format': most_likely_format,
                'confidence_score': confidence_score,
                'format_scores': format_percentages,
                'sample_count': len(date_samples),
                'samples': date_samples[:5]  # Include first 5 samples for debugging
            }
            
            return result
            
        except Exception as e:
            print(f"   ‚ùå Error analyzing date format: {str(e)}")
            return None
    
    def _normalize_name(self, name):
        """Chu·∫©n h√≥a t√™n ƒë·ªÉ so s√°nh"""
        
        if not name or pd.isna(name):
            return ""
        
        # Chuy·ªÉn v·ªÅ lowercase v√† lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a
        normalized = str(name).lower().strip()
        
        # Lo·∫°i b·ªè d·∫•u ti·∫øng Vi·ªát ƒë·ªÉ so s√°nh d·ªÖ h∆°n
        normalized = unicodedata.normalize('NFD', normalized)
        normalized = ''.join(c for c in normalized if unicodedata.category(c) != 'Mn')
        
        # Lo·∫°i b·ªè c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát v√† kho·∫£ng tr·∫Øng th·ª´a
        normalized = re.sub(r'[^\w\s]', '', normalized)
        normalized = re.sub(r'\s+', ' ', normalized).strip()
        
        return normalized
    
    def _is_gvcn_teacher(self, teacher_data):
        """Ki·ªÉm tra xem gi√°o vi√™n c√≥ ph·∫£i l√† GVCN hay kh√¥ng d·ª±a v√†o t√™n"""
        try:
            # L·∫•y t√™n t·ª´ c√°c field kh√°c nhau
            teacher_full_name = teacher_data.get('fullName', '') or ''
            teacher_info = teacher_data.get('teacherInfo', {})
            teacher_display_name = teacher_info.get('displayName', '') if teacher_info else ''
            teacher_name = teacher_full_name or teacher_display_name
            
            if not teacher_name:
                return False
                
            return self._is_gvcn_name_in_import(teacher_name)
            
        except Exception:
            return False
    
    def _extract_ht_hp_info(self, teachers_data):
        """Tr√≠ch xu·∫•t th√¥ng tin Hi·ªáu tr∆∞·ªùng (HT) v√† Hi·ªáu ph√≥ (HP) t·ª´ danh s√°ch gi√°o vi√™n"""
        try:
            if not teachers_data or not isinstance(teachers_data, dict):
                return {'ht': [], 'hp': []}
            
            teachers_list = teachers_data.get('data', [])
            if not teachers_list:
                return {'ht': [], 'hp': []}
            
            ht_teachers = []  # Hi·ªáu tr∆∞·ªùng
            hp_teachers = []  # Hi·ªáu ph√≥
            
            print("   üîç ƒêang t√¨m Hi·ªáu tr∆∞·ªùng (HT) v√† Hi·ªáu ph√≥ (HP)...")
            
            # Debug: Hi·ªÉn th·ªã structure c·ªßa 5 teachers ƒë·∫ßu ti√™n
            print("   üîç DEBUG: Structure c·ªßa teachers:")
            for i, teacher in enumerate(teachers_list[:5], 1):
                teacher_roles = teacher.get('roles', [])
                teacher_name = teacher.get('fullName', '') or teacher.get('teacherInfo', {}).get('displayName', '') or 'Unknown'
                
                print(f"      Teacher {i}: '{teacher_name}'")
                print(f"         roles: {teacher_roles}")
                print(f"         roles type: {type(teacher_roles)}")
                
                # Debug t·∫•t c·∫£ c√°c keys trong teacher object
                print(f"         All keys: {list(teacher.keys())}")
                
                # Check n·∫øu c√≥ teacherInfo
                if 'teacherInfo' in teacher:
                    teacher_info = teacher['teacherInfo']
                    print(f"         teacherInfo keys: {list(teacher_info.keys())}")
                    if 'roles' in teacher_info:
                        print(f"         teacherInfo.roles: {teacher_info.get('roles')}")
            
            for teacher in teachers_list:
                # L·∫•y roles t·ª´ nhi·ªÅu v·ªã tr√≠ c√≥ th·ªÉ
                teacher_roles = teacher.get('roles', [])
                teacher_info = teacher.get('teacherInfo', {})
                teacher_info_roles = teacher_info.get('roles', []) if teacher_info else []
                
                # Combine roles t·ª´ c·∫£ hai ngu·ªìn
                all_roles = []
                if isinstance(teacher_roles, list):
                    all_roles.extend(teacher_roles)
                if isinstance(teacher_info_roles, list):
                    all_roles.extend(teacher_info_roles)
                
                # N·∫øu roles l√† string, convert th√†nh list
                if isinstance(teacher_roles, str):
                    all_roles.append(teacher_roles)
                if isinstance(teacher_info_roles, str):
                    all_roles.append(teacher_info_roles)
                
                if not all_roles:
                    continue
                
                # L·∫•y th√¥ng tin gi√°o vi√™n
                teacher_full_name = teacher.get('fullName', '') or ''
                teacher_info = teacher.get('teacherInfo', {})
                teacher_display_name = teacher_info.get('displayName', '') if teacher_info else ''
                teacher_name = teacher_full_name or teacher_display_name
                
                if not teacher_name:
                    continue
                
                # Ki·ªÉm tra vai tr√≤ HT (case insensitive)
                if any(role.upper() == 'HT' for role in all_roles if isinstance(role, str)):
                    # L·∫•y th√¥ng tin ƒëƒÉng nh·∫≠p t·ª´ teacherInfo
                    userName = teacher_info.get('userName', '') if teacher_info else ''
                    pwd = teacher_info.get('pwd', '') if teacher_info else ''
                    
                    ht_info = {
                        'name': teacher_name,
                        'fullName': teacher_full_name,
                        'displayName': teacher_display_name,
                        'userName': userName,
                        'pwd': pwd,
                        'roles': all_roles,
                        'raw_data': teacher
                    }
                    ht_teachers.append(ht_info)
                    print(f"      üëë T√¨m th·∫•y Hi·ªáu tr∆∞·ªùng: {teacher_name}")
                    print(f"         Roles: {all_roles}")
                    print(f"         Username: {userName}")
                    print(f"         Password: {pwd}")
                
                # Ki·ªÉm tra vai tr√≤ HP (case insensitive)
                if any(role.upper() == 'HP' for role in all_roles if isinstance(role, str)):
                    # L·∫•y th√¥ng tin ƒëƒÉng nh·∫≠p t·ª´ teacherInfo
                    userName = teacher_info.get('userName', '') if teacher_info else ''
                    pwd = teacher_info.get('pwd', '') if teacher_info else ''
                    
                    hp_info = {
                        'name': teacher_name,
                        'fullName': teacher_full_name,
                        'displayName': teacher_display_name,
                        'userName': userName,
                        'pwd': pwd,
                        'roles': all_roles,
                        'raw_data': teacher
                    }
                    hp_teachers.append(hp_info)
                    print(f"      üî∏ T√¨m th·∫•y Hi·ªáu ph√≥: {teacher_name}")
                    print(f"         Roles: {all_roles}")
                    print(f"         Username: {userName}")
                    print(f"         Password: {pwd}")
            
            # T√≥m t·∫Øt k·∫øt qu·∫£
            print(f"   üìä K·∫øt qu·∫£ t√¨m ki·∫øm:")
            print(f"      üëë Hi·ªáu tr∆∞·ªùng (HT): {len(ht_teachers)} ng∆∞·ªùi")
            print(f"      üî∏ Hi·ªáu ph√≥ (HP): {len(hp_teachers)} ng∆∞·ªùi")
            
            return {
                'ht': ht_teachers,
                'hp': hp_teachers,
                'total_ht': len(ht_teachers),
                'total_hp': len(hp_teachers)
            }
            
        except Exception as e:
            print_status(f"‚ùå L·ªói tr√≠ch xu·∫•t th√¥ng tin HT/HP: {e}", "error")
            return {'ht': [], 'hp': []}
    
    # Legacy method - replaced by unified workflow file
    # def _save_ht_hp_info(self, ht_hp_info, school_name):
    #     """Deprecated: HT/HP info is now saved in unified workflow file"""
    #     pass
    
    def _is_gvcn_name_in_import(self, name):
        """Ki·ªÉm tra xem t√™n c√≥ ph·∫£i l√† GVCN hay kh√¥ng (d√πng cho c·∫£ teacher data v√† import parsing)"""
        try:
            if not name:
                return False
                
            # Normalize t√™n ƒë·ªÉ ki·ªÉm tra
            normalized_name = str(name).upper().strip()
            
            # C√°c pattern GVCN th∆∞·ªùng g·∫∑p
            gvcn_patterns = [
                'GVCN',
                'GV CH·ª¶ NHI·ªÜM', 
                'GI√ÅO VI√äN CH·ª¶ NHI·ªÜM',
                'CH·ª¶ NHI·ªÜM',
                'CHUNHIEM'
            ]
            
            # Ki·ªÉm tra xem t√™n c√≥ ch·ª©a b·∫•t k·ª≥ pattern n√†o kh√¥ng
            for pattern in gvcn_patterns:
                if pattern in normalized_name:
                    return True
                    
            return False
            
        except Exception:
            return False
    
    def _normalize_date(self, date_str, detected_format=None):
        """Chu·∫©n h√≥a ng√†y sinh ƒë·ªÉ so s√°nh v·ªõi x·ª≠ l√Ω t·ªët h∆°n cho c√°c format kh√°c nhau"""
        
        if not date_str or pd.isna(date_str):
            return ""
        
        date_str = str(date_str).strip()
        
        # X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho Excel datetime format: "2007-10-06 00:00:00"
        # Lo·∫°i b·ªè ph·∫ßn timestamp " HH:MM:SS" ƒë·ªÉ tr√°nh corruption
        if ' ' in date_str and ':' in date_str:
            # T√°ch ph·∫ßn date v√† time
            date_part = date_str.split(' ')[0]
            time_part = date_str.split(' ', 1)[1] if len(date_str.split(' ')) > 1 else ""
            
            # N·∫øu time part c√≥ d·∫°ng "00:00:00" ho·∫∑c timestamp h·ª£p l·ªá, ch·ªâ l·∫•y ph·∫ßn date
            if re.match(r'\d{2}:\d{2}:\d{2}', time_part):
                date_str = date_part
                # print(f"üîß Stripped timestamp: '{date_str}' (was '{date_str} {time_part}')")
        
        # Lo·∫°i b·ªè c√°c k√Ω t·ª± kh√¥ng mong mu·ªën nh∆∞ng gi·ªØ l·∫°i d·∫•u / v√† -
        date_str = re.sub(r'[^\d/\-]', '', date_str)
        
        if not date_str:
            return ""
        
        # Debug: In ra ƒë·ªÉ theo d√µi qu√° tr√¨nh parse
        # print(f"üîç Parsing date: '{date_str}' with detected format: {detected_format}")
        
        # ∆Øu ti√™n s·ª≠ d·ª•ng detected format n·∫øu c√≥
        if detected_format:
            if detected_format == 'DD/MM/YYYY':
                return self._parse_date_as_dd_mm_yyyy(date_str)
            elif detected_format == 'MM/DD/YYYY':
                return self._parse_date_as_mm_dd_yyyy(date_str)
            elif detected_format == 'YYYY-MM-DD':
                return self._parse_date_as_yyyy_mm_dd(date_str)
            elif detected_format == 'Excel_DateTime':
                # ƒê√£ x·ª≠ l√Ω ·ªü tr√™n b·∫±ng c√°ch lo·∫°i b·ªè timestamp
                return self._parse_date_as_dd_mm_yyyy(date_str)
        
        # Fallback: logic c≈© n·∫øu kh√¥ng c√≥ detected format
        # ∆Øu ti√™n x·ª≠ l√Ω format DD/MM/YYYY tr∆∞·ªõc (format chu·∫©n cho Vietnam)
        # Pattern cho DD/MM/YYYY ho·∫∑c D/M/YYYY v·ªõi d·∫•u / ho·∫∑c -
        match = re.match(r'(\d{1,2})[/\-](\d{1,2})[/\-](\d{4})', date_str)
        if match:
            day, month, year = match.groups()
            try:
                # Validate ng√†y th√°ng
                day_int = int(day)
                month_int = int(month)
                year_int = int(year)
                
                if 1 <= day_int <= 31 and 1 <= month_int <= 12 and 1900 <= year_int <= 2030:
                    parsed_date = datetime(year_int, month_int, day_int)
                    # Tr·∫£ v·ªÅ format chu·∫©n YYYY-MM-DD ƒë·ªÉ ƒë·∫£m b·∫£o nh·∫•t qu√°n
                    normalized = parsed_date.strftime('%Y-%m-%d')
                    # print(f"  ‚úÖ Parsed DD/MM/YYYY: '{date_str}' ‚Üí '{normalized}'")
                    return normalized
            except ValueError:
                pass
        
        # Pattern cho YYYY-MM-DD (format t·ª´ OnLuyen ho·∫∑c ƒë√£ chu·∫©n h√≥a)
        match = re.match(r'(\d{4})[/\-](\d{1,2})[/\-](\d{1,2})', date_str)
        if match:
            year, month, day = match.groups()
            try:
                day_int = int(day)
                month_int = int(month)
                year_int = int(year)
                
                if 1 <= day_int <= 31 and 1 <= month_int <= 12 and 1900 <= year_int <= 2030:
                    parsed_date = datetime(year_int, month_int, day_int)
                    normalized = parsed_date.strftime('%Y-%m-%d')
                    # print(f"  ‚úÖ Parsed YYYY-MM-DD: '{date_str}' ‚Üí '{normalized}'")
                    return normalized
            except ValueError:
                pass
        
        # Pattern cho DD/MM/YY ho·∫∑c D/M/YY 
        match = re.match(r'(\d{1,2})[/\-](\d{1,2})[/\-](\d{2})', date_str)
        if match:
            day, month, year = match.groups()
            try:
                day_int = int(day)
                month_int = int(month)
                year_int = int(year)
                
                # X·ª≠ l√Ω nƒÉm 2 ch·ªØ s·ªë (07 = 2007, 95 = 1995)
                if year_int < 50:  # 00-49 = 2000-2049
                    full_year = year_int + 2000
                else:  # 50-99 = 1950-1999
                    full_year = year_int + 1900
                
                if 1 <= day_int <= 31 and 1 <= month_int <= 12:
                    parsed_date = datetime(full_year, month_int, day_int)
                    normalized = parsed_date.strftime('%Y-%m-%d')
                    # print(f"  ‚úÖ Parsed DD/MM/YY: '{date_str}' ‚Üí '{normalized}'")
                    return normalized
            except ValueError:
                pass
        
        # Th·ª≠ c√°c format chu·∫©n v·ªõi strptime nh∆∞ fallback
        date_formats = [
            '%d/%m/%Y',     # 24/11/2007
            '%d-%m-%Y',     # 24-11-2007
            '%Y-%m-%d',     # 2007-11-24
            '%d/%m/%y',     # 24/11/07
            '%d-%m-%y',     # 24-11-07
            '%m/%d/%Y',     # 11/24/2007 (US format)
            '%Y/%m/%d',     # 2007/11/24
        ]
        
        for fmt in date_formats:
            try:
                parsed_date = datetime.strptime(date_str, fmt)
                normalized = parsed_date.strftime('%Y-%m-%d')
                # print(f"  ‚úÖ Parsed with format {fmt}: '{date_str}' ‚Üí '{normalized}'")
                return normalized
            except ValueError:
                continue
        
        # N·∫øu v·∫´n kh√¥ng parse ƒë∆∞·ª£c, tr·∫£ v·ªÅ string g·ªëc ƒë√£ l√†m s·∫°ch
        print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ parse ng√†y: '{date_str}' - gi·ªØ nguy√™n ƒë·ªÉ so s√°nh")
        return date_str.lower()
    
    def _parse_date_as_dd_mm_yyyy(self, date_str):
        """Parse ng√†y theo format DD/MM/YYYY"""
        match = re.match(r'(\d{1,2})[/\-](\d{1,2})[/\-](\d{4})', date_str)
        if match:
            day, month, year = match.groups()
            try:
                day_int = int(day)
                month_int = int(month)
                year_int = int(year)
                
                if 1 <= day_int <= 31 and 1 <= month_int <= 12 and 1900 <= year_int <= 2030:
                    parsed_date = datetime(year_int, month_int, day_int)
                    return parsed_date.strftime('%Y-%m-%d')
            except ValueError:
                pass
        return date_str.lower()
    
    def _parse_date_as_mm_dd_yyyy(self, date_str):
        """Parse ng√†y theo format MM/DD/YYYY"""
        match = re.match(r'(\d{1,2})[/\-](\d{1,2})[/\-](\d{4})', date_str)
        if match:
            month, day, year = match.groups()  # ƒê·∫£o v·ªã tr√≠ month v√† day
            try:
                day_int = int(day)
                month_int = int(month)
                year_int = int(year)
                
                if 1 <= day_int <= 31 and 1 <= month_int <= 12 and 1900 <= year_int <= 2030:
                    parsed_date = datetime(year_int, month_int, day_int)
                    return parsed_date.strftime('%Y-%m-%d')
            except ValueError:
                pass
        return date_str.lower()
    
    def _parse_date_as_yyyy_mm_dd(self, date_str):
        """Parse ng√†y theo format YYYY-MM-DD"""
        match = re.match(r'(\d{4})[/\-](\d{1,2})[/\-](\d{1,2})', date_str)
        if match:
            year, month, day = match.groups()
            try:
                day_int = int(day)
                month_int = int(month)
                year_int = int(year)
                
                if 1 <= day_int <= 31 and 1 <= month_int <= 12 and 1900 <= year_int <= 2030:
                    parsed_date = datetime(year_int, month_int, day_int)
                    return parsed_date.strftime('%Y-%m-%d')
            except ValueError:
                pass
        return date_str.lower()
    
    def _standardize_import_date_formats(self, df):
        """Chu·∫©n h√≥a format ng√†y th√°ng trong import dataframe"""
        print("üîß ƒêang chu·∫©n h√≥a format ng√†y th√°ng trong d·ªØ li·ªáu import...")
        
        date_columns = []
        
        # T√¨m c√°c c·ªôt c√≥ th·ªÉ ch·ª©a ng√†y
        for col in df.columns:
            col_lower = col.lower()
            if any(keyword in col_lower for keyword in ['ng√†y', 'sinh', 'date', 'birth']):
                date_columns.append(col)
        
        print(f"üìÖ T√¨m th·∫•y {len(date_columns)} c·ªôt ng√†y: {date_columns}")
        
        # Ph√¢n t√≠ch format ng√†y cho t·ª´ng c·ªôt
        for col in date_columns:
            print(f"\nüîç Ph√¢n t√≠ch format cho c·ªôt '{col}'...")
            
            # Ph√¢n t√≠ch format th·ª±c t·∫ø t·ª´ d·ªØ li·ªáu
            format_analysis = self._analyze_date_format_in_import(df, col)
            
            if format_analysis:
                detected_format = format_analysis.get('most_likely_format')
                confidence = format_analysis.get('confidence_score', 0)
                
                print(f"‚úÖ Detected format: {detected_format} (confidence: {confidence}%)")
                print(f"üìä Format scores: {format_analysis.get('format_scores', {})}")
                
                if confidence > 50:  # Ch·ªâ √°p d·ª•ng n·∫øu confidence > 50%
                    print(f"üîÑ Applying detected format '{detected_format}' to column '{col}'...")
                    
                    # √Åp d·ª•ng format ƒë√£ detect ƒë·ªÉ normalize
                    for idx in df.index:
                        if pd.notna(df.at[idx, col]):
                            original_date = df.at[idx, col]
                            normalized_date = self._normalize_date(str(original_date), detected_format)
                            df.at[idx, col] = normalized_date
                            
                            # Debug: In m·ªôt v√†i v√≠ d·ª•
                            if idx < 3:  # In 3 v√≠ d·ª• ƒë·∫ßu ti√™n
                                print(f"  üìù Row {idx}: '{original_date}' ‚Üí '{normalized_date}' (format: {detected_format})")
                else:
                    print(f"‚ö†Ô∏è Confidence th·∫•p ({confidence}%), s·ª≠ d·ª•ng logic fallback...")
                    # Fallback: normalize b·∫±ng logic c≈©
                    for idx in df.index:
                        if pd.notna(df.at[idx, col]):
                            original_date = df.at[idx, col]
                            normalized_date = self._normalize_date(str(original_date))
                            df.at[idx, col] = normalized_date
            else:
                print(f"‚ùå Kh√¥ng th·ªÉ ph√¢n t√≠ch format cho c·ªôt '{col}', s·ª≠ d·ª•ng logic fallback...")
                # Fallback: normalize b·∫±ng logic c≈©
                for idx in df.index:
                    if pd.notna(df.at[idx, col]):
                        original_date = df.at[idx, col]
                        normalized_date = self._normalize_date(str(original_date))
                        df.at[idx, col] = normalized_date
        
        print("‚úÖ Ho√†n th√†nh chu·∫©n h√≥a format ng√†y th√°ng\n")
        return df
    
    def test_date_normalization(self):
        """Test method ƒë·ªÉ ki·ªÉm tra vi·ªác chu·∫©n h√≥a ng√†y th√°ng"""
        print_separator("TEST DATE NORMALIZATION")
        
        test_dates = [
            "6/7/2007",     # D/M/YYYY
            "06/07/2007",   # DD/MM/YYYY  
            "6-7-2007",     # D-M-YYYY
            "06-07-2007",   # DD-MM-YYYY
            "2007-07-06",   # YYYY-MM-DD
            "6/7/07",       # D/M/YY
            "06/07/07",     # DD/MM/YY
            "24/12/1995",   # DD/MM/YYYY
            "1/1/2000",     # D/M/YYYY
            "10/6/2007",    # D/M/YYYY - case c·ª• th·ªÉ c·ªßa user
            "10/06/2007",   # DD/MM/YYYY - case t·ª´ OnLuyen
            "",             # Empty
            "invalid",      # Invalid
            "30/2/2020"     # Invalid date
        ]
        
        print("üîç TEST CASES:")
        for date_str in test_dates:
            normalized = self._normalize_date(date_str)
            print(f"   '{date_str}' ‚Üí '{normalized}'")
        
        print("\n‚úÖ Test completed. C√°c ng√†y h·ª£p l·ªá s·∫Ω ƒë∆∞·ª£c chuy·ªÉn v·ªÅ format YYYY-MM-DD")
    
    def _print_workflow_summary_case_2(self, results):
        """In t√≥m t·∫Øt k·∫øt qu·∫£ workflow Case 2"""
        print(f"\nüìä T√ìM T·∫ÆT K·∫æT QU·∫¢ WORKFLOW CASE 2:")
        print("=" * 70)
        
        print(f"üè´ Tr∆∞·ªùng: {results['school_info'].get('name', 'N/A')}")
        print(f"üë§ Admin: {results['school_info'].get('admin', 'N/A')}")
        print()
        
        # Tr·∫°ng th√°i t·ª´ng b∆∞·ªõc
        steps = [
            ("1Ô∏è‚É£ Tr√≠ch xu·∫•t Google Sheets", results['sheets_extraction']),
            ("2Ô∏è‚É£ OnLuyen API Login", results['api_login']),
            ("3Ô∏è‚É£ L·∫•y d·ªØ li·ªáu Gi√°o vi√™n", results['teachers_data']),
            ("4Ô∏è‚É£ L·∫•y d·ªØ li·ªáu H·ªçc sinh", results['students_data']),
            ("5Ô∏è‚É£ T·∫£i file import", results['import_file_downloaded']),
            ("6Ô∏è‚É£ So s√°nh d·ªØ li·ªáu", results['data_comparison']),
            ("7Ô∏è‚É£ L∆∞u d·ªØ li·ªáu JSON", results['json_saved']),
            ("8Ô∏è‚É£ Chuy·ªÉn ƒë·ªïi Excel", results['excel_converted']),
            ("9Ô∏è‚É£ Upload Google Drive", results['drive_uploaded'])
        ]
        
        for step_name, status in steps:
            status_icon = "‚úÖ" if status else "‚ùå"
            status_text = "Th√†nh c√¥ng" if status else "Th·∫•t b·∫°i"
            print(f"{status_icon} {step_name}: {status_text}")
        
        # T√≥m t·∫Øt so s√°nh d·ªØ li·ªáu
        if results.get('comparison_results'):
            comp = results['comparison_results']
            print(f"\nüîç K·∫æT QU·∫¢ SO S√ÅNH (Theo H·ªç t√™n + Ng√†y sinh):")
            print(f"   ÔøΩ Import Teachers: {comp.get('import_teachers_count', 0)}")
            print(f"   üìä Import Students: {comp.get('import_students_count', 0)}")
            
            # Hi·ªÉn th·ªã th√¥ng tin ƒë·∫∑c bi·ªát v·ªÅ gi√°o vi√™n
            if comp.get('export_all_teachers', False):
                print(f"   üë®‚Äçüè´ Gi√°o vi√™n: XU·∫§T T·∫§T C·∫¢ {comp.get('teachers_matched', 0)} (t√¨m th·∫•y GVCN)")
            else:
                print(f"   üë®‚Äçüè´ Gi√°o vi√™n kh·ªõp: {comp.get('teachers_matched', 0)}/{comp.get('import_teachers_count', 0)}")
            
            # Hi·ªÉn th·ªã th√¥ng tin v·ªÅ h·ªçc sinh
            has_students_in_system = comp.get('has_students_in_system', True)
            if not has_students_in_system:
                print(f"   üë®‚Äçüéì H·ªçc sinh: KH√îNG C√ì TRONG H·ªÜ TH·ªêNG (File Excel s·∫Ω kh√¥ng c√≥ sheet HOC-SINH)")
            else:
                print(f"   üë®‚Äçüéì H·ªçc sinh kh·ªõp: {comp.get('students_matched', 0)}/{comp.get('import_students_count', 0)}")
            
            print(f"   üîß Ph∆∞∆°ng ph√°p: {comp.get('method', 'name_and_birthdate')}")
        
        # Th√¥ng tin HT/HP
        if results.get('ht_hp_info'):
            ht_hp_info = results['ht_hp_info']
            print(f"\nüëë TH√îNG TIN L√ÉNH ƒê·∫†O:")
            print(f"   üëë Hi·ªáu tr∆∞·ªùng (HT): {ht_hp_info.get('total_ht', 0)} ng∆∞·ªùi")
            print(f"   üî∏ Hi·ªáu ph√≥ (HP): {ht_hp_info.get('total_hp', 0)} ng∆∞·ªùi")
            
            # Hi·ªÉn th·ªã danh s√°ch HT
            if ht_hp_info.get('ht'):
                print(f"   üìã Danh s√°ch Hi·ªáu tr∆∞·ªùng:")
                for i, ht in enumerate(ht_hp_info['ht'], 1):
                    print(f"      {i}. {ht['name']}")
            
            # Hi·ªÉn th·ªã danh s√°ch HP
            if ht_hp_info.get('hp'):
                print(f"   üìã Danh s√°ch Hi·ªáu ph√≥:")
                for i, hp in enumerate(ht_hp_info['hp'], 1):
                    print(f"      {i}. {hp['name']}")
        
        # File outputs
        if results.get('json_file_path') or results.get('excel_file_path') or results.get('ht_hp_file'):
            print(f"\nüìÑ FILES ƒê√É T·∫†O:")
            if results.get('json_file_path'):
                print(f"   üìã JSON: {results['json_file_path']}")
            if results.get('excel_file_path'):
                print(f"   üìä Excel: {results['excel_file_path']}")
            if results.get('ht_hp_file'):
                print(f"   üëë HT/HP Info: {results['ht_hp_file']}")
        
        # Upload results
        if results.get('upload_results'):
            upload_info = results['upload_results']
            print(f"\nüì§ DRIVE UPLOAD:")
            print(f"   ‚úÖ Th√†nh c√¥ng: {upload_info.get('success', 0)} files")
            print(f"   ‚ùå Th·∫•t b·∫°i: {upload_info.get('failed', 0)} files")
        
        # T·ªïng k·∫øt
        success_count = sum([results['sheets_extraction'], results['api_login'], 
                           results['teachers_data'], results['students_data'],
                           results['import_file_downloaded'], results['data_comparison'],
                           results['json_saved'], results['excel_converted'], 
                           results['drive_uploaded']])
        total_steps = 9
        
        print(f"\nüéØ T·ªîNG K·∫æT: {success_count}/{total_steps} b∆∞·ªõc th√†nh c√¥ng")
        
        if success_count == total_steps:
            print_status("üéâ WORKFLOW CASE 2 HO√ÄN CH·ªàNH - ƒê√É SO S√ÅNH, L·ªåC V√Ä T·∫†O EXCEL!", "success")
        elif success_count >= 7:
            print_status("‚ö†Ô∏è Workflow Case 2 ho√†n th√†nh ch√≠nh (c√≥ th·ªÉ thi·∫øu upload)", "warning")
        elif success_count >= 5:
            print_status("‚ö†Ô∏è Workflow Case 2 ho√†n th√†nh m·ªôt ph·∫ßn", "warning")
        else:
            print_status("‚ùå Workflow Case 2 th·∫•t b·∫°i", "error")

    def run(self):
        """Ch·∫°y ·ª©ng d·ª•ng"""
        try:
            print_header("SCHOOL PROCESS APPLICATION - ENHANCED", "H·ªá th·ªëng x·ª≠ l√Ω d·ªØ li·ªáu tr∆∞·ªùng h·ªçc")
            
            # Hi·ªÉn th·ªã th√¥ng tin config n·∫øu debug mode
            if self.config.is_debug_mode():
                self.config.print_config_summary()
            
            self.show_main_menu()
            
        except KeyboardInterrupt:
            print("\n\n‚èπÔ∏è  ·ª®ng d·ª•ng b·ªã d·ª´ng b·ªüi ng∆∞·ªùi d√πng")
        except Exception as e:
            print(f"\nüí• L·ªñI NGHI√äM TR·ªåNG: {e}")
            print("üìû Vui l√≤ng ki·ªÉm tra c·∫•u h√¨nh ho·∫∑c li√™n h·ªá support")
        finally:
            print(f"\nüìä ·ª®ng d·ª•ng k·∫øt th√∫c: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


def main():
    """Entry point"""
    app = SchoolProcessApp()
    app.run()


if __name__ == "__main__":
    main()